@article{Jones2012b,
abstract = {Previous research has shown that reach endpoints vary with the starting position of the reaching hand and the location of the reach target in space. We examined the effect of movement direction of a proprioceptive target-hand, immediately preceding a reach, on reach endpoints to that target. Participants reached to visual, proprioceptive (left target-hand), or visual-proprioceptive targets (left target-hand illuminated for one second prior to reach onset) with their right hand. Six sites served as starting and final target locations (35 target movement directions in total). Reach endpoints do not vary with the movement direction of the proprioceptive target, but instead appear to be anchored to some other reference (e.g. body). We also compared reach endpoints across the single and dual modality conditions. Overall, the pattern of reaches for visual-proprioceptive targets resembled those for proprioceptive targets, while reach precision resembled those for the visual targets. We did not, however, find evidence for integration of vision and proprioception based on a maximum likelihood estimator in these tasks.},
author = {Jones, S. A. H. and Byrne, P. A. and Fiehler, K. and Henriques, D. Y. P.},
doi = {10.1152/jn.00901.2011},
isbn = {1522-1598 (Electronic)$\backslash$r0022-3077 (Linking)},
issn = {0022-3077},
journal = {Journal of Neurophysiology},
number = {12},
pages = {3316--3324},
pmid = {22402658},
title = {{Reach endpoint errors do not vary with movement path of the proprioceptive target}},
url = {http://jn.physiology.org/cgi/doi/10.1152/jn.00901.2011},
volume = {107},
year = {2012}
}
@article{Byrne2013,
abstract = {When reaching for an object in the environment, the brain often has access to multiple independent estimates of that object's location. For example, if someone places their coffee cup on a table, then later they know where it is because they see it, but also because they remember how their reaching limb was oriented when they placed the cup. Intuitively, one would expect more accurate reaches if either of these estimates were improved (e.g., if a light were turned on so the cup were more visible). It is now well-established that the brain tends to combine two or more estimates about the same stimulus as a maximum-likelihood estimator (MLE), which is the best thing to do when estimates are unbiased. Even in the presence of small biases, relying on the MLE rule is still often better than choosing a single estimate. For this work, we designed a reaching task in which human subjects could integrate proprioceptive and allocentric (landmark-relative) visual information to reach for a remembered target. Even though both of these modalities contain some level of bias, we demonstrate via simulation that our subjects should use an MLE rule in preference to relying on one modality or the other in isolation. Furthermore, we show that when visual information is poor, subjects do, indeed, combine information in this way. However, when we improve the quality of visual information, subjects counter-intuitively switch to a sub-optimal strategy that occasionally includes reliance on a single modality. {\textcopyright} 2012 Elsevier Ltd.},
author = {{Byrne}, Patrick A. and Henriques, Denise Y.P.},
doi = {10.1016/j.neuropsychologia.2012.10.008},
isbn = {1873-3514 (Electronic)$\backslash$n0028-3932 (Linking)},
issn = {00283932},
journal = {Neuropsychologia},
keywords = {Multisensory integration,Proprioception,Reaching,Vision,Visuomotor transformation},
number = {1},
pages = {26--37},
pmid = {23142707},
publisher = {Elsevier},
title = {{When more is less: Increasing allocentric visual information can switch visual-proprioceptive combination from an optimal to sub-optimal process}},
url = {http://dx.doi.org/10.1016/j.neuropsychologia.2012.10.008},
volume = {51},
year = {2013}
}
@article{Ernst2002,
abstract = {When a person looks at an object while exploring it with their hand, vision and touch both provide information for estimating the properties of the object. Vision frequently dominates the integrated visual-haptic percept, for example when judging size, shape or position, but in some circumstances the percept is clearly affected by haptics. Here we propose that a general principle, which minimizes variance in the final estimate, determines the degree to which vision or haptics dominates. This principle is realized by using maximum-likelihood estimation to combine the inputs. To investigate cue combination quantitatively, we first measured the variances associated with visual and haptic estimation of height. We then used these measurements to construct a maximum-likelihood integrator. This model behaved very similarly to humans in a visual-haptic task. Thus, the nervous system seems to combine visual and haptic information in a fashion that is similar to a maximum-likelihood integrator. Visual dominance occurs when the variance associated with visual estimation is lower than that associated with haptic estimation.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Ernst, Marc O. and Banks, Martin S.},
doi = {10.1038/415429a},
eprint = {NIHMS150003},
isbn = {0028-0836 (Print)$\backslash$r0028-0836 (Linking)},
issn = {00280836},
journal = {Nature},
pmid = {11807554},
title = {{Humans integrate visual and haptic information in a statistically optimal fashion}},
year = {2002}
}
@article{Zbib2016,
abstract = {When subjects reach in a novel visuomotor environment (e.g. while viewing a cursor representing their hand that is rotated from their hand's actual position), they typically adjust their movements (i.e. bring the cursor to the target), thus reducing reaching errors. Additionally, research has shown that reaching with altered visual feedback of the hand results in sensory changes, such that proprioceptive estimates of hand position are shifted in the direction of the visual feedback experienced (Cressman and Henriques in J Neurophysiol 102:3505–3518, 2009). This study looked to establish the time course of these sensory changes. Additionally, the time courses of implicit sensory and motor changes were compared. Subjects reached to a single visual target while seeing a cursor that was either aligned with their hand position (50 trials) or rotated 30° clockwise relative to their hand (150 trials). Reach errors and proprioceptive estimates of felt hand position were assessed following the aligned reach training trials and at seven different times during the rotated reach training trials by having subjects reach to the target without visual feedback, and provide estimates of their hand relative to a visual reference marker, respectively. Results revealed a shift in proprioceptive estimates throughout the rotated reach training trials; however, significant sensory changes were not observed until after 70 trials. In contrast, results showed a greater change in reaches after a limited number of reach training trials with the rotated cursor. These findings suggest that proprioceptive recalibration arises more slowly than reach adaptation.},
author = {Zbib, Basel and Henriques, Denise Y.P. and Cressman, Erin K.},
doi = {10.1007/s00221-016-4624-6},
isbn = {0022101646246},
issn = {14321106},
journal = {Experimental Brain Research},
number = {8},
pmid = {27014777},
title = {{Proprioceptive recalibration arises slowly compared to reach adaptation}},
volume = {234},
year = {2016}
}
@article{Izawa2012,
abstract = {When we use a novel tool, the motor commands may not produce the expected outcome. In healthy individuals, with practice the brain learns to alter the motor commands. This change depends critically on the cerebellum as damage to this structure impairs adaptation. However, it is unclear precisely what the cerebellum contributes to the process of adaptation in human motor learning. Is the cerebellum crucial for learning to associate motor commands with novel sensory consequences, called forward model, or is the cerebellum important for learning to associate sensory goals with novel motor commands, called inverse model? Here, we compared performance of cerebellar patients and healthy controls in a reaching task with a gradual perturbation schedule. This schedule allowed both groups to adapt their motor commands. Following training, we measured two kinds of behavior: in one case, people were presented with reach targets near the direction in which they had trained. The resulting generalization patterns of patients and controls were similar, suggesting comparable inverse models. In the second case, participants reached without a target and reported the location of their hand. In controls, the pattern of change in reported hand location was consistent with simulation results of a forward model that had learned to associate motor commands with new sensory consequences. In patients, this change was significantly smaller. Therefore, in our sample of patients, we observed that while adaptation of motor commands can take place despite cerebellar damage, cerebellar integrity appears critical for learning to predict visual sensory consequences of motor commands.},
author = {Izawa, J. and Criscimagna-Hemminger, S. E. and Shadmehr, R.},
doi = {10.1523/JNEUROSCI.6353-11.2012},
isbn = {1529-2401 (Electronic)$\backslash$r0270-6474 (Linking)},
issn = {0270-6474},
journal = {Journal of Neuroscience},
pmid = {22442085},
title = {{Cerebellar Contributions to Reach Adaptation and Learning Sensory Consequences of Action}},
year = {2012}
}
@article{Izawa2012a,
abstract = {When we use a novel tool, the motor commands may not produce the expected outcome. In healthy individuals, with practice the brain learns to alter the motor commands. This change depends critically on the cerebellum as damage to this structure impairs adaptation. However, it is unclear precisely what the cerebellum contributes to the process of adaptation in human motor learning. Is the cerebellum crucial for learning to associate motor commands with novel sensory consequences, called forward model, or is the cerebellum important for learning to associate sensory goals with novel motor commands, called inverse model? Here, we compared performance of cerebellar patients and healthy controls in a reaching task with a gradual perturbation schedule. This schedule allowed both groups to adapt their motor commands. Following training, we measured two kinds of behavior: in one case, people were presented with reach targets near the direction in which they had trained. The resulting generalization patterns of patients and controls were similar, suggesting comparable inverse models. In the second case, participants reached without a target and reported the location of their hand. In controls, the pattern of change in reported hand location was consistent with simulation results of a forward model that had learned to associate motor commands with new sensory consequences. In patients, this change was significantly smaller. Therefore, in our sample of patients, we observed that while adaptation of motor commands can take place despite cerebellar damage, cerebellar integrity appears critical for learning to predict visual sensory consequences of motor commands.},
author = {Izawa, J. and Criscimagna-Hemminger, S. E. and Shadmehr, R.},
doi = {10.1523/JNEUROSCI.6353-11.2012},
isbn = {1529-2401 (Electronic)$\backslash$r0270-6474 (Linking)},
issn = {0270-6474},
journal = {Journal of Neuroscience},
pmid = {22442085},
title = {{Cerebellar Contributions to Reach Adaptation and Learning Sensory Consequences of Action}},
year = {2012}
}
@article{Synofzik2008,
abstract = {Each action has sensory consequences that need to be distinguished from sensations arising from the environment. This is accomplished by the comparing of internal predictions about these consequences with the actual afference, thereby isolating the afferent component that is self-produced [1-4]. Because the sensory consequences of actions vary as a result of changes of the effector's efficacy, internal predictions need to be updated continuously and on a short time scale. Here, we tested the hypothesis that this updating of predictions about the sensory consequences of actions is mediated by the cerebellum, a notion that parallels the cerebellum's role in motor learning [5-8]. Patients with cerebellar lesions and their matched controls were equally able to detect experimental modifications of visual feedback about their pointing movements. When such feedback was constantly rotated, both groups instantly attributed the visual feedback to their own actions. However, in interleaved trials without actual feedback, patients did no longer account for this feedback rotation-neither perceptually nor with respect to motor performance. Both deficits can be explained by an impaired updating of internal predictions about the sensory consequences of actions caused by cerebellar pathology. Thus, the cerebellum guarantees both precise performance and veridical perceptual interpretation of actions. {\textcopyright} 2008 Elsevier Ltd. All rights reserved.},
author = {Synofzik, Matthis and Lindner, Axel and Thier, Peter},
doi = {10.1016/j.cub.2008.04.071},
isbn = {0960-9822},
issn = {09609822},
journal = {Current Biology},
keywords = {SYSNEURO},
pmid = {18514520},
title = {{The Cerebellum Updates Predictions about the Visual Consequences of One's Behavior}},
year = {2008}
}
@article{Duhamel1992,
abstract = {Every eye movement produces a shift in the visual image on the retina. The receptive field, or retinal response area, of an individual visual neuron moves with the eyes so that after an eye movement it covers a new portion of visual space. For some parietal neurons, the location of the receptive field is shown to shift transiently before an eye movement. In addition, nearly all parietal neurons respond when an eye movement brings the site of a previously flashed stimulus into the receptive field. Parietal cortex both anticipates the retinal consequences of eye movements and updates the retinal coordinates of remembered stimuli to generate a continuously accurate representation of visual space.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Duhamel and Colby, C. and Goldberg, M.},
doi = {10.1126/science.1553535},
eprint = {arXiv:1011.1669v3},
isbn = {0036-8075 (Print)$\backslash$r0036-8075 (Linking)},
issn = {0036-8075},
journal = {Science},
pmid = {1553535},
title = {{The updating of the representation of visual space in parietal cortex by intended eye movements}},
year = {1992}
}
@article{Jones2010,
abstract = {We examined the effect of gaze direction relative to target location on reach endpoint errors made to proprioceptive and multisensory targets. We also explored if and how visual and proprioceptive information about target location are integrated to guide reaches. Participants reached to their unseen left hand in one of three target locations (left of body midline, body midline, or right or body midline), while it remained at a target site (online), or after it was removed from this location (remembered), and also after the target hand had been briefly lit before reaching (multisensory target). The target hand was guided to a target location using a robot-generated path. Reaches were made with the right hand in complete darkness, while gaze was varied in one of four eccentric directions. Horizontal reach errors systematically varied relative to gaze for all target modalities; not only for visually remembered and online proprioceptive targets as has been found in previous studies, but for the first time, also for remembered proprioceptive targets and proprioceptive targets that were briefly visible. These results suggest that the brain represents the locations of online and remembered proprioceptive reach targets, as well as visual-proprioceptive reach targets relative to gaze, along with other motor-related representations. Our results, however, do not suggest that visual and proprioceptive information are optimally integrated when coding the location of multisensory reach targets in this paradigm. {\textcopyright} 2010 Elsevier Ltd.},
author = {Jones, Stephanie A H and Henriques, Denise Y P},
doi = {10.1016/j.neuropsychologia.2010.10.001},
isbn = {1873-3514 (Electronic)$\backslash$n0028-3932 (Linking)},
issn = {00283932},
journal = {Neuropsychologia},
keywords = {Reaching,Sensory integration,Updating},
pmid = {20934442},
title = {{Memory for proprioceptive and multisensory targets is partially coded relative to gaze}},
year = {2010}
}
@article{Jones2012,
abstract = {Previous research has shown that reach endpoints vary with the starting position of the reaching hand and the location of the reach target in space. We examined the effect of movement direction of a proprioceptive target-hand, immediately preceding a reach, on reach endpoints to that target. Participants reached to visual, proprioceptive (left target-hand), or visual-proprioceptive targets (left target-hand illuminated for one second prior to reach onset) with their right hand. Six sites served as starting and final target locations (35 target movement directions in total). Reach endpoints do not vary with the movement direction of the proprioceptive target, but instead appear to be anchored to some other reference (e.g. body). We also compared reach endpoints across the single and dual modality conditions. Overall, the pattern of reaches for visual-proprioceptive targets resembled those for proprioceptive targets, while reach precision resembled those for the visual targets. We did not, however, find evidence for integration of vision and proprioception based on a maximum likelihood estimator in these tasks.},
author = {Jones, S. A. H. and Byrne, P. A. and Fiehler, K. and Henriques, D. Y. P.},
doi = {10.1152/jn.00901.2011},
isbn = {1522-1598 (Electronic)$\backslash$r0022-3077 (Linking)},
issn = {0022-3077},
journal = {Journal of Neurophysiology},
pmid = {22402658},
title = {{Reach endpoint errors do not vary with movement path of the proprioceptive target}},
year = {2012}
}
@article{Brooks2015,
abstract = {There is considerable evidence that the cerebellum has a vital role in motor learning by constructing an estimate of the sensory consequences of movement. Theory suggests that this estimate is compared with the actual feedback to compute the sensory prediction error. However, direct proof for the existence of this comparison is lacking. We carried out a trial-by-trial analysis of cerebellar neurons during the execution and adaptation of voluntary head movements and found that neuronal sensitivities dynamically tracked the comparison of predictive and feedback signals. When the relationship between the motor command and resultant movement was altered, neurons robustly responded to sensory input as if the movement was externally generated. Neuronal sensitivities then declined with the same time course as the concurrent behavioral learning. These findings demonstrate the output of an elegant computation in which rapid updating of an internal model enables the motor system to learn to expect unexpected sensory inputs.},
author = {Brooks, Jessica X. and Carriot, Jerome and Cullen, Kathleen E.},
doi = {10.1038/nn.4077},
isbn = {1546-1726 (Electronic)$\backslash$r1097-6256 (Linking)},
issn = {15461726},
journal = {Nature Neuroscience},
pmid = {26237366},
title = {{Learning to expect the unexpected: Rapid updating in primate cerebellum during voluntary self-motion}},
year = {2015}
}
@article{Clayton2013,
abstract = {Reaching movements are rapidly adapted following training with rotated visual feedback of the hand. Our laboratory has also found that this visuomotor adaptation results in changes in estimates of felt hand position (proprioceptive recalibration) in the direction of the visuomotor distortion (Cressman and Henriques in J Neurophysiol 102:3505-3518, 2009; Cressman et al. in Exp Brain Res 205:533-544, 2010). In the current study, we investigated proprioceptive acuity and proprioceptive recalibration in a group of individuals with Ehlers-Danlos syndrome (EDS), a degenerative condition associated with collagen malformation. Some studies have suggested that these patients may have proprioceptive impairments, but the exact nature of the impairment is unclear (Rombaut et al. in Clin Rheumatol 29:289-295, 2010a). In this study, we measured the ability of EDS patients to estimate their felt hand position and tested whether these estimates changed following visuomotor adaptation. We found EDS patients were less precise in estimating their felt hand position in the peripheral workspace compared to healthy controls. Despite this poorer sensitivity, they recalibrated hand proprioception to the same extent as healthy controls. This is consistent with other populations who experience proprioceptive deficits (e.g. the elderly, Parkinson's disease patients), suggesting that sensory noise does not influence the extent of either motor or sensory plasticity.},
author = {Clayton, Holly A. and Cressman, Erin K. and Henriques, Denise Y.P.},
doi = {10.1007/s00221-013-3656-4},
isbn = {0014-4819},
issn = {00144819},
journal = {Experimental Brain Research},
keywords = {Ehlers-Danlos syndrome,Generalized joint hypermobility,Multisensory integration,Proprioception,Reaches},
pmid = {23912909},
title = {{Proprioceptive sensitivity in Ehlers-Danlos syndrome patients}},
year = {2013}
}
@article{Hart2016,
abstract = {During motor adaptation the discrepancy between predicted and actually perceived sensory feedback is thought to be minimized, but it can be difficult to measure predictions of the sensory consequences of actions. Studies attempting to do so have found that self-directed, unseen hand position is mislocalized in the direction of altered visual feedback. However, our lab has shown that motor adaptation also leads to changes in perceptual estimates of hand position, even when the target hand is passively displaced. We attribute these changes to a recalibration of hand proprioception, since in the absence of a volitional movement, efferent or predictive signals are likely not involved. The goal here is to quantify the extent to which changes in hand localization reflect a change in the predicted sensory (visual) consequences or a change in the perceived (proprioceptive) consequences. We did this by comparing changes in localization produced when the hand movement was self-generated ('active localization') versus robot-generated ('passive localization') to the same locations following visuomotor adaptation to a rotated cursor. In this passive version, there should be no predicted consequences of these robot-generated hand movements. We found that although changes in localization were somewhat larger in active localization, the passive localization task also elicited substantial changes. Our results suggest that the change in hand localization following visuomotor adaptation may not be based entirely on updating predicted sensory consequences, but may largely reflect changes in our proprioceptive state estimate.},
author = {{'t Hart}, Bernard Marius and Henriques, Denise Y.P.},
doi = {10.1371/journal.pone.0163556},
issn = {19326203},
journal = {PLoS ONE},
number = {9},
pmid = {27658214},
title = {{Separating predicted and perceived sensory consequences of motor learning}},
volume = {11},
year = {2016}
}
@article{Synofzik2008a,
abstract = {Each action has sensory consequences that need to be distinguished from sensations arising from the environment. This is accomplished by the comparing of internal predictions about these consequences with the actual afference, thereby isolating the afferent component that is self-produced [1-4]. Because the sensory consequences of actions vary as a result of changes of the effector's efficacy, internal predictions need to be updated continuously and on a short time scale. Here, we tested the hypothesis that this updating of predictions about the sensory consequences of actions is mediated by the cerebellum, a notion that parallels the cerebellum's role in motor learning [5-8]. Patients with cerebellar lesions and their matched controls were equally able to detect experimental modifications of visual feedback about their pointing movements. When such feedback was constantly rotated, both groups instantly attributed the visual feedback to their own actions. However, in interleaved trials without actual feedback, patients did no longer account for this feedback rotation-neither perceptually nor with respect to motor performance. Both deficits can be explained by an impaired updating of internal predictions about the sensory consequences of actions caused by cerebellar pathology. Thus, the cerebellum guarantees both precise performance and veridical perceptual interpretation of actions. {\textcopyright} 2008 Elsevier Ltd. All rights reserved.},
author = {Synofzik, Matthis and Lindner, Axel and Thier, Peter},
doi = {10.1016/j.cub.2008.04.071},
isbn = {0960-9822},
issn = {09609822},
journal = {Current Biology},
keywords = {SYSNEURO},
number = {11},
pages = {814--818},
pmid = {18514520},
title = {{The Cerebellum Updates Predictions about the Visual Consequences of One's Behavior}},
volume = {18},
year = {2008}
}
@article{Taylor2012,
author = {Taylor, Publisher and Lindstrom, Mary J and Bates, Douglas M and Lindstrom, Mary J and Bates, M},
doi = {10.1080/01621459.1988.10478693},
keywords = {-,e,growth curve,longitudinal data,random effects,x,x t v -},
number = {August 2013},
pages = {37--41},
title = {{Newton — Raphson and EM Algorithms for Linear Mixed- Newton-Raphson and E M Algorithms for Linear Mixed-Effects Models for Repeated-Measures Data}},
year = {2012}
}
@article{Luke2017,
author = {Luke, Steven G},
doi = {10.3758/s13428-016-0809-y},
keywords = {Linear mixed-effects models,Statistics,Type 1 error,and,baayen,data,davidson,increasingly popular for,linear mixed-effects models,lme4,mixed-effects models have become,p -values,p-values,statistics,the analysis of experimental,type 1 error},
number = {September 2016},
pages = {1494--1502},
publisher = {Behavior Research Methods},
title = {{Evaluating significance in linear mixed-effects models in R}},
year = {2017}
}
@article{Lerch2016,
author = {Lerch, Rachel A and Sims, Chris R},
doi = {10.1007/s00221-016-4553-4},
issn = {1432-1106},
journal = {Experimental Brain Research},
keywords = {Decision making,Motor planning,Visual memory,Visuospatial memory,decision making,motor planning,visual memory,visuospatial memory},
publisher = {Springer Berlin Heidelberg},
title = {{Decision theory , motor planning , and visual memory : deciding where to reach when memory errors are costly}},
year = {2016}
}
@article{Mcculloch2012,
author = {Mcculloch, Charles E and Mcculloch, Charles E},
doi = {10.1080/01621459.1997.10473613},
keywords = {importance sampling,metropolis-hastings algorithm,monte carlo em,newton-raphson algorithm,penalized,quasi-likelihood,simulated maximum likelihood},
title = {{Maximum Likelihood Algorithms for Generalized Linear Mixed Models Maximum Likelihood Algorithms for Generalized Linear Mixed Models}},
volume = {1459},
year = {2012}
}
@article{Sakamoto2015,
author = {Sakamoto, Takashi and Kondo, Toshiyuki},
doi = {10.3389/fnhum.2015.00279},
keywords = {interference,interference, motor learning, passive movement, ro,motor learning,passive movement,robot,visuomotor learning},
number = {May},
pages = {1--7},
title = {{Visuomotor learning by passive motor experience}},
volume = {9},
year = {2015}
}
@article{Abdulkarim2017,
author = {Abdulkarim, Zakaryah and Ehrsson, H Henrik},
doi = {10.1007/s00221-017-5137-7},
isbn = {0022101751377},
issn = {1432-1106},
journal = {Experimental Brain Research},
keywords = {Multisensory,Perception,Sensory recalibration,Visi,multisensory,perception,proprioception,sensory recalibration,vision},
number = {0},
pages = {0},
publisher = {Springer Berlin Heidelberg},
title = {{Recalibration of hand position sense during unconscious active and passive movement}},
url = {http://dx.doi.org/10.1007/s00221-017-5137-7},
volume = {0},
year = {2017}
}
@article{Wolpert1995,
abstract = {On the basis of computational studies it has been proposed that the central nervous system internally simulates the dynamic behavior of the motor system in planning, control, and learning; the existence and use of such an internal model is still under debate. A sensorimotor integration task was investigated in which participants estimated the location of one of their hands at the end of movements made in the dark and under externally imposed forces. The temporal propagation of errors in this task was analyzed within the theoretical framework of optimal state estimation. These results provide direct support for the existence of an internal model.},
author = {Wolpert, D M and Ghahramani, Z and Jordan, M I},
issn = {0036-8075},
journal = {Science (New York, N.Y.)},
month = {sep},
number = {5232},
pages = {1880--2},
pmid = {7569931},
title = {{An internal model for sensorimotor integration.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/7569931},
volume = {269},
year = {1995}
}
@article{DeJong2006,
author = {de Jong, Ritske and Gladwin, Thomas E and {'t Hart}, Bernard Marius},
doi = {10.1016/j.brainres.2006.03.030},
title = {{Movement-related EEG indices of preparation in task switching and motor control}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-33746857682{\&}partnerID=MN8TOARS},
year = {2006}
}
@article{DeJong2006a,
author = {de Jong, Ritske and Gladwin, Thomas E and {'t Hart}, Bernard Marius},
doi = {10.1016/j.brainres.2006.03.030},
month = {aug},
pmid = {16630582},
title = {{Movement-related EEG indices of preparation in task switching and motor control.}},
url = {http://europepmc.org/abstract/med/16630582},
year = {2006}
}
@article{Gladwin2008,
author = {Gladwin, Thomas Edward and {'t Hart}, Bernard Marius and de Jong, Ritske},
doi = {10.1016/j.cortex.2007.10.005},
title = {{Dissociations between motor-related EEG measures in a cued movement sequence task}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-44249117336{\&}partnerID=MN8TOARS},
year = {2008}
}
@article{,
journal = {Visual Cognition},
title = {{Gaze allocation in natural stimuli: comparing free exploration to head-fixed viewing conditions.}},
year = {2009}
}
@article{Gladwin2009,
author = {Gladwin, T E and {'t Hart}, B M and de Jong, R},
doi = {10.1016/j.cortex.2008.11.007},
title = {{Erratum to: Dissociations between motor-related EEG measures in a cued movement sequence task [Cortex, 44: 521-536, 2008] (DOI:10.1016/j.cortex.2007.10.005)}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-65249098273{\&}partnerID=MN8TOARS},
year = {2009}
}
@article{Engmann2009,
author = {Engmann, Sonja and {'t Hart}, Bernard Marius and Sieren, T and Onat, Selim and K{\"{o}}nig, Peter and Einh{\"{a}}user, Wolfgang},
doi = {10.3758/APP.71.6.1337},
title = {{Saliency on a natural scene background: Effects of color and luminance contrast add linearly}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-70349504191{\&}partnerID=MN8TOARS},
year = {2009}
}
@article{Engmann2009a,
author = {Engmann, Sonja and {'t Hart}, Bernard Marius and Sieren, T and Onat, Selim and K{\"{o}}nig, Peter and Einh{\"{a}}user, Wolfgang},
doi = {10.3758/APP.71.6.1337},
month = {aug},
pmid = {19633349},
title = {{Saliency on a natural scene background: effects of color and luminance contrast add linearly.}},
url = {http://europepmc.org/abstract/med/19633349},
year = {2009}
}
@article{Preuschoff2011,
author = {Preuschoff, K and {'t Hart}, B M and Einh{\"{a}}user, W},
doi = {10.3389/fnins.2011.00115},
title = {{Pupil dilation signals surprise: Evidence for noradrenaline's role in decision making}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84862215780{\&}partnerID=MN8TOARS},
year = {2011}
}
@article{Preuschoff2011a,
author = {Preuschoff, Kerstin and {'t Hart}, Bernard Marius and Einh{\"{a}}user, Wolfgang},
doi = {10.3389/fnins.2011.00115},
pmid = {21994487},
title = {{Pupil Dilation Signals Surprise: Evidence for Noradrenaline's Role in Decision Making.}},
url = {http://europepmc.org/abstract/med/21994487},
year = {2011}
}
@article{tHart2011,
author = {{'t Hart}, Bernard Marius and Abresch, T G and Einh{\"{a}}user, Wolfgang},
doi = {10.1371/journal.pone.0025373},
pmid = {21998653},
title = {{Faces in places: humans and machines make similar face detection errors.}},
url = {http://europepmc.org/abstract/med/21998653},
year = {2011}
}
@article{tHart2011a,
author = {{'t Hart}, B M and Abresch, T G J and Einh{\"{a}}user, W},
doi = {10.1371/journal.pone.0025373},
title = {{Faces in places: Humans and machines make similar face detection errors}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80053645922{\&}partnerID=MN8TOARS},
year = {2011}
}
@article{tHart2012,
author = {{'t Hart}, Bernard Marius and Einh{\"{a}}user, Wolfgang},
doi = {10.1007/s00221-012-3254-x},
month = {nov},
pmid = {23001370},
title = {{Mind the step: complementary effects of an implicit task on eye and head movements in real-life gaze allocation.}},
url = {http://europepmc.org/abstract/med/23001370},
year = {2012}
}
@article{tHart2013,
author = {{'t Hart}, Bernard Marius and Schmidt, Hannah C and Roth, Christine and Einh{\"{a}}user, Wolfgang},
doi = {10.3389/fpsyg.2013.00455},
pmid = {23882251},
title = {{Fixations on objects in natural scenes: dissociating importance from salience.}},
url = {http://europepmc.org/abstract/med/23882251},
year = {2013}
}
@article{tHart2013a,
author = {{'t Hart}, Bernard Marius and Schmidt, H.C.E.F. and Roth, Christine and Einh{\"{a}}user, Wolfgang},
doi = {10.3389/fpsyg.2013.00455},
title = {{Fixations on objects in natural scenes: Dissociating importance from salience}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84885340415{\&}partnerID=MN8TOARS},
year = {2013}
}
@article{tHart2013b,
author = {{'t Hart}, Bernard Marius and Schmidt, Hannah C and Klein-Harmeyer, Ingo and Einh{\"{a}}user, Wolfgang},
doi = {10.1098/rstb.2013.0067},
month = {oct},
pmid = {24018728},
title = {{Attention in natural scenes: contrast affects rapid visual processing and fixations alike.}},
url = {http://europepmc.org/abstract/med/24018728},
year = {2013}
}
@article{Colby1995,
author = {Colby, Carol L and Duhamel, Jean-rene and Goldberg, Michael E},
journal = {Cerebral Cortex},
title = {{Parietal Cortex Peripheral Attention}},
year = {1995}
}
@article{Guenther2014,
abstract = {Feedback perturbation studies of speech acoustics have revealed a great deal about how speakers monitor and control their productions of segmental (e.g., formant frequencies) and non-segmental (e.g., pitch) linguistic elements. The majority of previous work, however, overlooks the role of acoustic feedback in consonant production and makes use of acoustic manipulations that effect either entire utterances or the entire acoustic signal, rather than more temporally and phonetically restricted alterations. This study, therefore, seeks to expand the feedback perturbation literature by examining perturbation of consonant acoustics that is applied in a time-restricted and phonetically specific manner. The spectral center of the alveopalatal fricative [∫] produced in vowel-fricative-vowel nonwords was incrementally raised until it reached the potential for [s]-like frequencies, but the characteristics of high-frequency energy outside the target fricative remained unaltered. An "offline," more widely accessible signal processing method was developed to perform this manipulation. The local feedback perturbation resulted in changes to speakers' fricative production that were more variable, idiosyncratic, and restricted than the compensation seen in more global acoustic manipulations reported in the literature. Implications and interpretations of the results, as well as future directions for research based on the findings, are discussed.},
author = {Guenther, Frank H and Cai, Shanqing and Casserly, Elizabeth D and Ries, Lpbra and Bastian, AJ Amy J},
doi = {10.1097/WCO.0b013e328315a293.Understanding},
isbn = {1350-7540; 1350-7540},
issn = {00014966},
journal = {Current opinion in neurology},
keywords = {628,633,Brain Mapping,Cerebellum,Cerebellum: physiology,Cerebral Cortex,Cerebral Cortex: physiology,Feedback,Feedback: physiology,Humans,Magnetic Resonance Imaging,Models,Neurological,Psychomotor Performance,Speech,Speech: physiology,Verbal Behavior,curr opin neurol 21,health,lippincott williams,memory,motor,reaching,stroke,walking,wilkins,{\ss} 2008 wolters kluwer},
number = {February},
pages = {1--36},
pmid = {18989103},
title = {{A Manual of Audapter}},
url = {http://europepmc.org/articles/PMC2954436{\%}5Cnhttp://www.ncbi.nlm.nih.gov/pubmed/16887139},
volume = {129},
year = {2014}
}
@article{Cressman2009,
abstract = {directed reaches are rapidly adapted following exposure to misaligned visual feedback of the hand. It has been suggested that these changes in reaches result in sensory recalibration (i.e., realigning propriocep-tive estimates of hand position to match the visual estimates). In the current study we tested whether visuomotor adaptation results in recalibration of hand proprioception by comparing subjects' estimates of the position at which they felt their hand was aligned with a reference marker (visual or proprioceptive) before and after aiming with a misaligned cursor. The misaligned cursor was either translated or rotated to the right of the actual hand location. On the estimation trials, we did not allow subjects to freely move their hands into position. Instead, a robot manipulandum either passively positioned the hand (experiments 1 and 2) or subjects moved their hand along a robot-generated constrained pathway (experiments 3 and 4). We found that regardless of experimental manipulation, subjects' proprioceptive estimates of hand position were more biased to the left after visuo-motor adaptation. The leftward shift in subjects' estimates was in the same direction and one third of the magnitude of the adapted move-ment. This suggests that in addition to recalibrating the sensorimotor transformations underlying reaching movements, visuomotor adapta-tion results in partial proprioceptive recalibration. I N T R O D U C T I O N When reaching to a visual target we combine visual infor-mation regarding target location and hand position with limb proprioceptive information, to compute the motor error needed to produce a correct motor command (e.g., Jeannerod 1988). Typically, visual and proprioceptive estimates are aligned, such that one feels the hand is at the same position at which one sees it. However, situations arise in which these sensory signals conflict (e.g., when looking through a microscope or in a mirror). In cases when sensory cues conflict and one is reach-ing to a visual target, one tends to rely more on the visual estimate of the hand than on the actual or felt position. Thus movements are adjusted in accordance with the seen position of the hand and one learns a new visuomotor mapping (visuo-motor adaptation). For example, if a cursor is shifted right-wards relative to the actual hand location, subjects adjust their reaches, aiming to the left of the intended target to bring the cursor onto the target (Baraduc and Wolpert 2002; Ghahramani et al. 1996; Magescas and Prablanc 2006; Simani et al. 2007; Vetter et al. 1999). It is currently unclear how the brain deals with these conflicting sensory signals. One possibility is that vision merely overrules the proprioceptive sense of the hand position during visuomotor adaptation. On the other hand, perhaps reaching with altered visual feedback of the hand causes proprioception to be recali-brated such that subjects begin to feel their hand is at the same location at which they see it. In an attempt to address this issue, previous work has typically asked subjects to reach to visual and proprioceptive targets with their adapted hand following visuo-motor adaptation (Simani et al. 2007; van Beers et al. 2002). Although subjects' reaches were altered following visuomotor adaptation, it is unclear whether these changes reflect intersensory recalibration per se. Subjects were allowed to freely move their adapted arm. Thus errors in reaches could have arisen due to subjects using the adapted sensorimotor mapping. Given the possibility that reaching tasks may engage adapted sensorimotor mappings, Henriques and colleagues (Malfait et al. 2008; Wong and Henriques 2009) have recently attempted to assess proprioceptive recalibration in perceptual, nonreaching tasks. In their paradigms, subjects were required to report on the shape that the hand had traversed or hand-path geometry relative to a reference following visuomotor adaptation. Although these tasks do not directly assess changes in sense of the hand position, they do provide some insight into proprioceptive recalibration. Specifically, based on the differences in results between the two paradigms, it appears that proprioceptive recalibration may be dependent on the visuomotor distortion introduced and/or how subjects position their hand during the perceptual estimates. For example, Malfait et al. (2008) found evidence for proprioceptive recalibration in a task in which subjects reported whether the path that the hand was passively moved through matched a square path that a cursor traced out. This task was completed after subjects were exposed to a translated cursor when tracking a moving dot with their hand and learned to trace a rectangular path to guide the cursor around a square. In contrast to these results, Wong and Henriques (2009) found no changes in subjects' sense of hand direction after they were exposed to a rotated cursor in an aiming task and actively pushed the robot into position during the pro-prioceptive estimates. In the current task, we wanted to determine whether the sense of hand position was recalibrated following visuomotor adapta-tion in a reaching task. To do this, we modified the perceptual paradigms of Malfait et al. (2008) and Wong and Henriques (2009) and determined the position at which subjects perceived their unseen hand was aligned with reference markers in a task that did not allow subjects to reach, aim, align— or otherwise freely move—their adapted hand. In contrast to previous studies, our reference markers consisted of both visual and proprioceptive cues. Given the differences obtained between Malfait et al. (2008) and Wong and Henriques (2009), we used a robot manipulandum to either passively position the hand (experiments 1 and 2) or generate a constrained pathway along which subjects moved their hand (experiments 3 and 4). Once the hand reached the end of the path, a reference marker appeared and subjects reported whether their unseen hand was left or right of the reference marker.},
author = {Cressman, E. K. and Henriques, D. Y. P.},
doi = {10.1152/jn.00514.2009},
isbn = {1522-1598 (Electronic)},
issn = {0022-3077},
journal = {Journal of Neurophysiology},
number = {6},
pages = {3505--3518},
pmid = {19828727},
title = {{Sensory Recalibration of Hand Position Following Visuomotor Adaptation}},
url = {http://jn.physiology.org/cgi/doi/10.1152/jn.00514.2009},
volume = {102},
year = {2009}
}
@article{Berniker2008,
abstract = {Motor adaptation is usually defined as the process by which our nervous system produces accurate movements while the properties of our bodies and our environment continuously change. Many experimental and theoretical studies have characterized this process by assuming that the nervous system uses internal models to compensate for motor errors. Here we extend these approaches and construct a probabilistic model that not only compensates for motor errors but estimates the sources of these errors. These estimates dictate how the nervous system should generalize. For example, estimated changes of limb properties will affect movements across the workspace but not movements with the other limb. We provide evidence that many movement-generalization phenomena emerge from a strategy by which the nervous system estimates the sources of our motor errors.},
author = {Berniker, Max and Kording, Konrad},
doi = {10.1038/nn.2229},
isbn = {1546-1726 (Electronic)$\backslash$n1097-6256 (Linking)},
issn = {10976256},
journal = {Nature Neuroscience},
number = {12},
pages = {1454--1461},
pmid = {19011624},
title = {{Estimating the sources of motor errors for adaptation and generalization}},
volume = {11},
year = {2008}
}
@article{Barkley2014,
abstract = {We have shown that when subjects reach with continuous, misaligned visual feedback of their hand, their reaches are adapted and proprioceptive sense of hand position is recalibrated to partially match the visual feedback (Salomonczyk et al., 2011). It is unclear if similar changes arise after reaching with visual feedback that is provided only at the end of the reach (i.e., terminal feedback), when there are shorter temporal intervals for subjects to experience concurrent visual and proprioceptive feedback. Subjects reached to targets with an aligned hand-cursor that provided visual feedback at the end of each reach movement across a 99-trial training block, and with a rotated cursor over three successive blocks of 99 trials each. After each block, no cursor reaches, to measure aftereffects, and felt hand positions were measured. Felt hand position was determined by having subjects indicate the position of their unseen hand relative to a reference marker. We found that subjects adapted their reaches following training with rotated terminal visual feedback, yet slightly less (i.e., reach aftereffects were smaller), than subjects from a previous study who experienced continuous visual feedback. Nonetheless, current subjects recalibrated their sense of felt hand position in the direction of the altered visual feedback, but this proprioceptive change increased incrementally over the three rotated training blocks. Final proprioceptive recalibration levels were comparable to our previous studies in which subjects performed the same task with continuous visual feedback. Thus, compared to reach training with continuous, but altered visual feedback, subjects who received terminal altered visual feedback of the hand produced significant but smaller reach aftereffects and similar changes in hand proprioception when given extra training. Taken together, results suggest that terminal feedback of the hand is sufficient to drive motor adaptation, and also proprioceptive recalibration.},
author = {Barkley, Victoria and Salomonczyk, Danielle and Cressman, Erin K. and Henriques, Denise Y. P.},
doi = {10.3389/fnhum.2014.00705},
issn = {1662-5161},
journal = {Frontiers in Human Neuroscience},
keywords = {motor adaptation,proprioceptive recalibration,terminal feedback,vision,visuomotor rotation,visuomotor rotation, terminal feedback, motor adap},
number = {September},
pages = {1--11},
pmid = {25249969},
title = {{Reach adaptation and proprioceptive recalibration following terminal visual feedback of the hand}},
url = {http://journal.frontiersin.org/article/10.3389/fnhum.2014.00705/abstract},
volume = {8},
year = {2014}
}
@article{Burke1988,
abstract = {1. Microneurographic techniques were employed to record unitary activity from afferents associated with digital joints of six conscious human subjects. Of 120 single afferents sampled from the median and ulnar nerves at the wrist, eighteen (15{\%}) were classified as joint afferents; the majority of the sample (72.5{\%}) were of cutaneous origin, and 12.5{\%} were from muscle spindles and tendon organs. 2. Of the eighteen joint afferents six were tonically active in the rest position of the hand. All except two were recruited or accelerated their background discharge during passive joint movement. Three tonically active afferents were responsive to passive movement throughout the physiological range. The majority of the afferents, including the other three tonically active units, responded only towards the limits of joint rotation. 3. As a group, the sample of joint afferents had a limited capacity to signal the direction of joint movement. Nine of the sixteen joint afferents sensitive to movement responded in two axes of angular displacement, and two responded in all three axes. In any one axis of rotation eight afferents were activated in both directions of movement. However, one afferent, associated with the interphalangeal joint of the thumb, responded uni-directionally throughout the physiological range of joint movement and was thereby capable of adequately encoding joint position and movement. 4. Twenty-one of twenty-nine slowly adapting and eleven of eighteen rapidly adapting cutaneous afferents tested were activated by joint movement, but only towards the limits of joint rotation; half of the thirty-two movement-sensitive afferents were bi-directionally responsive. Muscle spindle afferents responded to stresses applied to the joint only if the resulting passive movement stretched the parent muscle. 5. It is concluded that human joint afferents possess a very limited capacity to provide kinaesthetic information, and that this is likely to be of significance only when muscle spindle afferents cannot contribute to kinaesthesia.},
author = {Burke, D. and Gandevia, S. C. and Macefield, G.},
doi = {10.1113/jphysiol.1988.sp017208},
isbn = {0022-3751 (Print) 0022-3751 (Linking)},
issn = {14697793},
journal = {The Journal of Physiology},
number = {1},
pages = {347--361},
pmid = {2976823},
title = {{Responses to passive movement of receptors in joint, skin and muscle of the human hand.}},
volume = {402},
year = {1988}
}
@article{Block2011,
abstract = {When estimating the position of one hand for the purpose of reaching to it with the other, humans have visual and proprioceptive estimates of the target hand's position. These are thought to be weighted and combined to form an integrated estimate in such a way that variance is minimized. If visual and proprioceptive estimates are in disagreement, it may be advantageous for the nervous system to bring them back into register by spatially realigning one or both. It is possible that realignment is determined by weights, in which case the lower-weighted modality should always realign more than the higher-weighted modality. An alternative possibility is that realignment and weighting processes are controlled independently, and either can be used to compensate for a sensory misalignment. Here, we imposed a misalignment between visual and proprioceptive estimates of target hand position in a reaching task designed to allow simultaneous, independent measurement of weights and realignment. In experiment 1, we used endpoint visual feedback to create a situation where task success could theoretically be achieved with either a weighting or realignment strategy, but vision had to be regarded as the correctly aligned modality to achieve success. In experiment 2, no endpoint visual feedback was given. We found that realignment operates independently of weights in the former case but not in the latter case, suggesting that while weighting and realignment may operate in conjunction in some circumstances, they are biologically independent processes that give humans behavioral flexibility in compensating for sensory perturbations.},
author = {Block, Hannah J and Bastian, Amy J},
doi = {10.1152/jn.00641.2010},
isbn = {1522-1598 (Electronic)$\backslash$r0022-3077 (Linking)},
issn = {1522-1598},
journal = {Journal of neurophysiology},
keywords = {Adult,Feedback, Sensory,Feedback, Sensory: physiology,Female,Hand,Hand: physiology,Humans,Male,Movement,Movement: physiology,Proprioception,Proprioception: physiology,Psychomotor Performance,Psychomotor Performance: physiology,Visual Perception,Visual Perception: physiology},
number = {1},
pages = {59--70},
pmid = {21490284},
title = {{Sensory weighting and realignment: independent compensatory processes.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3129718{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {106},
year = {2011}
}
@article{Bhanpuri2013,
abstract = {Because sensation is delayed, real-time movement control requires not just sensing, but also predicting limb position, a function hypothesized for the cerebellum. Such cerebellar predictions could contribute to perception of limb position (i.e., proprioception), particularly when a person actively moves the limb. Here we show that human cerebellar patients have proprioceptive deficits compared with controls during active movement, but not when the arm is moved passively. Furthermore, when healthy subjects move in a force field with unpredictable dynamics, they have active proprioceptive deficits similar to cerebellar patients. Therefore, muscle activity alone is likely insufficient to enhance proprioception and predictability (i.e., an internal model of the body and environment) is important for active movement to benefit proprioception. We conclude that cerebellar patients have an active proprioceptive deficit consistent with disrupted movement prediction rather than an inability to generally enhance peripheral proprioceptive signals during action and suggest that active proprioceptive deficits should be considered a fundamental cerebellar impairment of clinical importance.},
author = {Bhanpuri, N. H. and Okamura, A. M. and Bastian, A. J.},
doi = {10.1523/JNEUROSCI.0784-13.2013},
isbn = {1529-2401 (Electronic)$\backslash$r0270-6474 (Linking)},
issn = {0270-6474},
journal = {Journal of Neuroscience},
number = {36},
pages = {14301--14306},
pmid = {24005283},
title = {{Predictive Modeling by the Cerebellum Improves Proprioception}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.0784-13.2013},
volume = {33},
year = {2013}
}
@article{Blakemore1998,
abstract = {During self-generated movement it is postulated that an efference copy of the descending motor command, in conjunction with an internal model of both the motor system and environment, enables us to predict the consequences of our own actions (von Helmholtz, 1867; Sperry, 1950; von Holst, 1954; Wolpert, 1997). Such a prediction is evident in the precise anticipatory modulation of grip force seen when one hand pushes on an object gripped in the other hand (Johansson and Westling, 1984; Flanagan and Wing, 1933). Here we show that self-generation is not in itself sufficient for such a prediction. We used two robots to simulate virtual objects held in one hand and acted on by the other. Precise predictive grip force modulation of the restraining hand was highly dependent on the sensory feedback to the hand producing the load. The results show that predictive modulation requires not only that the movement is self-generated, but also that the efference copy and sensory feedback are consistent with a specific context; in this case, the manipulation of a single object. We propose a novel computational mechanism whereby the CNS uses multiple internal models, each corresponding to a different sensorimotor context, to estimate the probability that the motor system is acting within each context.},
author = {Blakemore, Sarah-Jayne and Goodbody, Susan J and Wolpert, Daniel M},
doi = {Not available},
isbn = {0270-6474 (Print)$\backslash$n0270-6474 (Linking)},
issn = {0270-6474},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
keywords = {a sinusoidal load is,applied to an object,bimanual coordination,designed to test the,force,forward models,grip,held in a fixed,internal model,location by,prediction,the first experiment was,the right hand,virtual reality},
number = {18},
pages = {7511--7518},
pmid = {9736669},
title = {{Predicting the consequences of our own actions: the role of sensorimotor context estimation.}},
volume = {18},
year = {1998}
}
@article{Huang2011,
abstract = {Although motor learning is likely to involve multiple processes, phenomena observed in error-based motor learning paradigms tend to be conceptualized in terms of only a single process: adaptation, which occurs through updating an internal model. Here we argue that fundamental phenomena like movement direction biases, savings (faster relearning), and interference do not relate to adaptation but instead are attributable to two additional learning processes that can be characterized as model-free: use-dependent plasticity and operant reinforcement. Although usually " hidden" behind adaptation, we demonstrate, with modified visuomotor rotation paradigms, that these distinct model-based and model-free processes combine to learn an error-based motor task. (1) Adaptation of an internal model channels movements toward successful error reduction in visual space. (2) Repetition of the newly adapted movement induces directional biases toward the repeated movement. (3) Operant reinforcement through association of the adapted movement with successful error reduction is responsible for savings. {\textcopyright} 2011 Elsevier Inc.},
author = {Huang, Vincent S. and Haith, Adrian and Mazzoni, Pietro and Krakauer, John W.},
doi = {10.1016/j.neuron.2011.04.012},
isbn = {1097-4199 (Electronic)$\backslash$r0896-6273 (Linking)},
issn = {08966273},
journal = {Neuron},
number = {4},
pages = {787--801},
pmid = {21609832},
publisher = {Elsevier Inc.},
title = {{Rethinking Motor Learning and Savings in Adaptation Paradigms: Model-Free Memory for Successful Actions Combines with Internal Models}},
url = {http://dx.doi.org/10.1016/j.neuron.2011.04.012},
volume = {70},
year = {2011}
}
@article{Izawa2008,
abstract = {Our sensory observations represent a delayed, noisy estimate of the environment. Delay causes instability and noise causes uncertainty. To deal with these problems, theory suggests that the processing of sensory information by the brain should be probabilistic: to start a movement or to alter it midflight, our brain should make predictions about the near future of sensory states and then continuously integrate the delayed sensory measures with predictions to form an estimate of the current state. To test the predictions of this theory, we asked participants to reach to the center of a blurry target. With increased uncertainty about the target, reach reaction times increased. Occasionally, we changed the position of the target or its blurriness during the reach. We found that the motor response to a given second target was influenced by the uncertainty about the first target. The specific trajectories of motor responses were consistent with predictions of a "minimum variance" state estimator. That is, the motor output that the brain programmed to start a reaching movement or correct it midflight was a continuous combination of two streams of information: a stream that predicted the near future of the state of the environment and a stream that provided a delayed measurement of that state.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Izawa, J. and Shadmehr, R.},
doi = {10.1523/JNEUROSCI.3063-08.2008},
eprint = {NIHMS150003},
isbn = {1529-2401 (Electronic)$\backslash$r0270-6474 (Linking)},
issn = {0270-6474},
journal = {Journal of Neuroscience},
keywords = {autopilot,computational model,integration,motor control,reaction time,uncertainty},
number = {44},
pages = {11360--11368},
pmid = {18971478},
title = {{On-Line Processing of Uncertain Information in Visuomotor Control}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.3063-08.2008},
volume = {28},
year = {2008}
}
@article{Izawa2011,
abstract = {Voluntary motor commands produce two kinds of consequences. Initially, a sensory consequence is observed in terms of activity in our primary sensory organs (e.g., vision, proprioception). Subsequently, the brain evaluates the sensory feedback and produces a subjective measure of utility or usefulness of the motor commands (e.g., reward). As a result, comparisons between predicted and observed consequences of motor commands produce two forms of prediction error. How do these errors contribute to changes in motor commands? Here, we considered a reach adaptation protocol and found that when high quality sensory feedback was available, adaptation of motor commands was driven almost exclusively by sensory prediction errors. This form of learning had a distinct signature: as motor commands adapted, the subjects altered their predictions regarding sensory consequences of motor commands, and generalized this learning broadly to neighboring motor commands. In contrast, as the quality of the sensory feedback degraded, adaptation of motor commands became more dependent on reward prediction errors. Reward prediction errors produced comparable changes in the motor commands, but produced no change in the predicted sensory consequences of motor commands, and generalized only locally. Because we found that there was a within subject correlation between generalization patterns and sensory remapping, it is plausible that during adaptation an individual's relative reliance on sensory vs. reward prediction errors could be inferred. We suggest that while motor commands change because of sensory and reward prediction errors, only sensory prediction errors produce a change in the neural system that predicts sensory consequences of motor commands.},
author = {Izawa, Jun and Shadmehr, Reza},
doi = {10.1371/journal.pcbi.1002012},
isbn = {1553-7358 (Electronic)$\backslash$r1553-734X (Linking)},
issn = {1553734X},
journal = {PLoS Computational Biology},
number = {3},
pages = {1--11},
pmid = {21423711},
title = {{Learning from sensory and reward prediction errors during motor adaptation}},
volume = {7},
year = {2011}
}
@article{Henriques2014,
abstract = {Decades of research have implicated both cortical and subcortical areas, such as the cerebellum, as playing an important role in motor learning, and even more recently, in predicting the sensory consequences of movement. Still, it is unknown whether the cerebellum also plays a role in recalibrating sensory estimates of hand position following motor learning. To test this, we measured proprioceptive estimates of static hand position in 19 cerebellar patients with local ischemic lesions and 19 healthy controls, both before and after reach training with altered visual feedback of the hand. This altered visual feedback, (30° cursor-rotation) was gradually introduced in order to facilitate reach adaptation in the patient group. We included two different types of training (in separate experiments): the typical visuomotor rotation training where participants had full volition of their hand movements when reaching with the cursor, and sensory exposure training where the direction of participants' hand movements were constrained and gradually deviated from the cursor motion (Cressman, E. K., Henriques, D. Y., 2010. Reach adaptation and proprioceptive recalibration following exposure to misaligned sensory input. J. Neurophysiol., vol. 103, pp. 1888-1895). We found that both healthy individuals and patients showed equivalent shifts in their felt hand position following both types of training. Likewise, as expected given that the cursor-rotation was introduced gradually, patients showed comparable reach aftereffects to those of controls in both types of training. The robust change in felt hand position across controls and cerebellar patients suggests that the cerebellum is not involved in proprioceptive recalibration of the hand.},
author = {Henriques, Denise Y P and Filippopulos, Filipp and Straube, Andreas and Eggert, Thomas},
doi = {10.1016/j.neuropsychologia.2014.09.029},
isbn = {1873-3514 (Electronic)$\backslash$r0028-3932 (Linking)},
issn = {18733514},
journal = {Neuropsychologia},
keywords = {Cerebellar patients,Cerebellum,Hand proprioception,Motor learning,Reaching,Visual distortion,Visuomotor adaptation},
pages = {195--204},
pmid = {25278133},
publisher = {Elsevier},
title = {{The cerebellum is not necessary for visually driven recalibration of hand proprioception}},
url = {http://dx.doi.org/10.1016/j.neuropsychologia.2014.09.029},
volume = {64},
year = {2014}
}
@article{Izawa2013,
abstract = {—Children with autism spectrum disorder (ASD) show deficits in development of motor skills, in addition to core deficits in social skill development. In a previous study (Haswell et al., 2009) we found that children with autism show a key difference in how they learn motor actions, with a bias for relying on joint position rather than visual feedback; further, this pattern of motor learning predicted impaired motor, imitation and social abilities. We were interested in finding out whether this altered motor learning pattern was specific to autism. To do so, we examined children with Attention Deficit Hyperactivity Disorder (ADHD), who also show deficits in motor control. Children learned a novel movement and we measured rates of motor learning, generalization patterns of motor learning, and variability of motor speed during learning. We found children with ASD show a slower rate of learning and, consistent with previous findings, an altered pattern of generalization that was predictive of impaired motor, imitation, and social impairment. In contrast, children with ADHD showed a normal rate of learning and a normal pattern of generalization; instead, they (and they alone), showed excessive variability in movement speed. The findings suggest that there is a specific pattern of altered motor learning associated with autism.},
author = {et al Izawa, Jun;},
doi = {10.1002/aur.1222.Motor},
isbn = {1939-3806 (Electronic)$\backslash$n1939-3806 (Linking)},
issn = {19393792},
journal = {Autism Research},
number = {2},
pages = {124--136},
pmid = {22359275},
title = {{motor learning relies on Integrated sensory inputs in adhd}},
volume = {5},
year = {2013}
}
@article{Herzfeld2014,
abstract = {A recent neurophysiology study provides data from the cerebellar vermis/nodulus, where neurons encode translation of the head, even when these translations are induced via an illusion. These data provide new neurophysiological evidence that the cerebellum is important for computations involving internal models of motion, estimating the state of the body. {\textcopyright} 2013 Elsevier Ltd.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Herzfeld, David J. and Shadmehr, Reza},
doi = {10.1016/j.tics.2013.10.015},
eprint = {NIHMS150003},
isbn = {1879-307X (Electronic) 1364-6613 (Linking)},
issn = {13646613},
journal = {Trends in Cognitive Sciences},
number = {2},
pages = {66--67},
pmid = {24263038},
publisher = {Elsevier Ltd},
title = {{Cerebellum estimates the sensory state of the body}},
url = {http://dx.doi.org/10.1016/j.tics.2013.10.015},
volume = {18},
year = {2014}
}
@article{Izawa2012b,
abstract = {When we use a novel tool, the motor commands may not produce the expected outcome. In healthy individuals, with practice the brain learns to alter the motor commands. This change depends critically on the cerebellum as damage to this structure impairs adaptation. However, it is unclear precisely what the cerebellum contributes to the process of adaptation in human motor learning. Is the cerebellum crucial for learning to associate motor commands with novel sensory consequences, called forward model, or is the cerebellum important for learning to associate sensory goals with novel motor commands, called inverse model? Here, we compared performance of cerebellar patients and healthy controls in a reaching task with a gradual perturbation schedule. This schedule allowed both groups to adapt their motor commands. Following training, we measured two kinds of behavior: in one case, people were presented with reach targets near the direction in which they had trained. The resulting generalization patterns of patients and controls were similar, suggesting comparable inverse models. In the second case, participants reached without a target and reported the location of their hand. In controls, the pattern of change in reported hand location was consistent with simulation results of a forward model that had learned to associate motor commands with new sensory consequences. In patients, this change was significantly smaller. Therefore, in our sample of patients, we observed that while adaptation of motor commands can take place despite cerebellar damage, cerebellar integrity appears critical for learning to predict visual sensory consequences of motor commands.},
author = {Izawa, J. and Criscimagna-Hemminger, S. E. and Shadmehr, R.},
doi = {10.1523/JNEUROSCI.6353-11.2012},
isbn = {1529-2401 (Electronic)$\backslash$r0270-6474 (Linking)},
issn = {0270-6474},
journal = {Journal of Neuroscience},
number = {12},
pages = {4230--4239},
pmid = {22442085},
title = {{Cerebellar Contributions to Reach Adaptation and Learning Sensory Consequences of Action}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.6353-11.2012},
volume = {32},
year = {2012}
}
@article{Izawa2008a,
abstract = {Adaptation is sometimes viewed as a process in which the nervous system learns to predict and cancel effects of a novel environment, returning movements to near baseline (unperturbed) conditions. An alternate view is that cancellation is not the goal of adaptation. Rather, the goal is to maximize performance in that environment. If performance criteria are well defined, theory allows one to predict the reoptimized trajectory. For example, if velocity-dependent forces perturb the hand perpendicular to the direction of a reaching movement, the best reach plan is not a straight line but a curved path that appears to overcompensate for the forces. If this environment is stochastic (changing from trial to trial), the reoptimized plan should take into account this uncertainty, removing the overcompensation. If the stochastic environment is zero-mean, peak velocities should increase to allow for more time to approach the target. Finally, if one is reaching through a via-point, the optimum plan in a zero-mean deterministic environment is a smooth movement but in a zero-mean stochastic environment is a segmented movement. We observed all of these tendencies in how people adapt to novel environments. Therefore, motor control in a novel environment is not a process of perturbation cancellation. Rather, the process resembles reoptimization: through practice in the novel environment, we learn internal models that predict sensory consequences of motor commands. Through reward-based optimization, we use the internal model to search for a better movement plan to minimize implicit motor costs and maximize rewards.},
author = {Izawa, J. and Rane, T. and Donchin, O. and Shadmehr, R.},
doi = {10.1523/JNEUROSCI.5359-07.2008},
isbn = {1529-2401 (Electronic)$\backslash$r0270-6474 (Linking)},
issn = {0270-6474},
journal = {Journal of Neuroscience},
keywords = {ataxia,cerebellar damage,internal model,motor adaptation,motor learning,optimal control},
number = {11},
pages = {2883--2891},
pmid = {18337419},
title = {{Motor Adaptation as a Process of Reoptimization}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.5359-07.2008},
volume = {28},
year = {2008}
}
@article{Duhamel1992a,
author = {Duhamel, Jean-Ren{\'{e}} and Colby, Carol L. and Goldberg, Michael E.},
journal = {Science},
number = {5040},
pages = {90--92},
title = {{The Updating of the Representation of Visual Space in Parietal Cortex by Intended Eye Movements}},
volume = {255},
year = {1992}
}
@article{Flanagan2003,
abstract = {Skilled motor behavior relies on the brain learning both to control the body and predict the consequences of this control. Prediction turns motor commands into expected sensory consequences [1], whereas control turns desired consequences into motor commands. To capture this symmetry, the neural processes underlying prediction and control are termed the forward and inverse internal models, respectively [2-5]. Here, we investigate how these two fundamental processes are related during motor learning. We used an object manipulation task in which subjects learned to move a hand-held object with novel dynamic properties along a prescribed path. We independently and simultaneously measured subjects' ability to control their actions and to predict their consequences. We found different time courses for predictor and controller learning, with prediction being learned far more rapidly than control. In early stages of manipulating the object, subjects could predict the consequences of their actions, as measured by the grip force they used to grasp the object, but could not generate appropriate actions for control, as measured by their hand trajectory. As predicted by several recent theoretical models of sensorimotor control [6-8], our results indicate that people can learn to predict the consequences of their actions before they can learn to control their actions.},
author = {Flanagan, Randall R. and Vetter, Philipp and Johansson, Roland S. and Wolpert, Daniel M.},
doi = {10.1016/S0960-9822(03)00007-1},
isbn = {0960-9822},
issn = {09609822},
journal = {Current Biology},
number = {2},
pages = {146--150},
pmid = {12546789},
title = {{Prediction precedes control in motor learning}},
volume = {13},
year = {2003}
}
@article{Henriques2012,
abstract = {Motor learning, in particular motor adaptation, is driven by information from multiple senses. For example, when arm control is faulty, vision, touch, and proprioception can all report on the arm's movements and help guide the adjustments necessary for correcting motor error. In recent years we have learned a lot about how the brain integrates information from multiple senses for the purpose of perception. However, less is known about how multisensory data guide motor learning. Most models of, and studies on, motor learning focus almost exclusively on the ensuing changes in motor performance without exploring the implications on sensory plasticity. Nor do they consider how discrepancies in sensory information (e.g., vision and proprioception) related to hand position may affect motor learning. Here, we discuss research from our lab and others that shows how motor learning paradigms affect proprioceptive estimates of hand position, and how even the mere discrepancy between visual and proprioceptive feedback can affect learning and plasticity. Our results suggest that sensorimotor learning mechanisms do not exclusively rely on motor plasticity and motor memory, and that sensory plasticity, in particular proprioceptive recalibration, plays a unique and important role in motor learning.},
author = {Henriques, Denise Y P and Cressman, Erin K.},
doi = {10.1080/00222895.2012.659232},
isbn = {1432-1106 (Electronic)$\backslash$n0014-4819 (Linking)},
issn = {00222895},
journal = {Journal of Motor Behavior},
keywords = {motor learning,multisensory,plasticity,reaching},
number = {6},
pages = {435--444},
pmid = {23237466},
title = {{Visuomotor adaptation and proprioceptive recalibration}},
volume = {44},
year = {2012}
}
@article{Diedrichsen2010,
abstract = {Human motor behavior is constantly adapted through the process of error-based learning. When the motor system encounters an error, its estimate about the body and environment will change, and the next movement will be immediately modified to counteract the underlying perturbation. Here, we show that a second mechanism, use-dependent learning, simultaneously changes movements to become more similar to the last movement. In three experiments, participants made reaching movements toward a horizontally elongated target, such that errors in the initial movement direction did not have to be corrected. Along this task-redundant dimension, we were able to induce use-dependent learning by passively guiding movements in a direction angled by 8 degrees from the previous direction. In a second study, we show that error-based and use-dependent learning can change motor behavior simultaneously in opposing directions by physically constraining the direction of active movements. After removal of the constraint, participants briefly exhibit an error-based aftereffect against the direction of the constraint, followed by a longer-lasting use-dependent aftereffect in the direction of the constraint. In the third experiment, we show that these two learning mechanisms together determine the solution the motor system adopts when learning a motor task.},
author = {Diedrichsen, J. and White, O. and Newman, D. and Lally, N.},
doi = {10.1523/JNEUROSCI.5406-09.2010},
isbn = {1529-2401 (Electronic)$\backslash$n0270-6474 (Linking)},
issn = {0270-6474},
journal = {Journal of Neuroscience},
number = {15},
pages = {5159--5166},
pmid = {20392938},
title = {{Use-Dependent and Error-Based Learning of Motor Behaviors}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.5406-09.2010},
volume = {30},
year = {2010}
}
@article{Henriques2012a,
abstract = {Motor learning, in particular motor adaptation, is driven by information from multiple senses. For example, when arm control is faulty, vision, touch, and proprioception can all report on the arm's movements and help guide the adjustments necessary for correcting motor error. In recent years we have learned a lot about how the brain integrates information from multiple senses for the purpose of perception. However, less is known about how multi- sensory data guide motor learning. Most models of, and studies on, motor learning focus almost exclusively on the ensuing changes in motor performance without exploring the implications on sen- sory plasticity. Nor do they consider how discrepancies in sensory information (e.g., vision and proprioception) related to hand po- sition may affect motor learning. Here, we discuss research from our lab and others that shows how motor learning paradigms af- fect proprioceptive estimates of hand position, and how even the mere discrepancy between visual and proprioceptive feedback can affect learning and plasticity. Our results suggest that sensorimotor learning mechanisms do not exclusively rely on motor plasticity and motor memory, and that sensory plasticity, in particular propri- oceptive recalibration, plays a unique and important role in motor learning.},
author = {Henriques, Denise Y P and Cressman, Erin K.},
doi = {10.1080/00222895.2012.659232},
journal = {Journal of Motor Behavior},
keywords = {motor learning,multisensory,plasticity,reaching},
number = {6},
pages = {435--444},
title = {{Visuomotor Adaptation and Proprioceptive Recalibration Visuomotor Adaptation and Proprioceptive Recalibration}},
volume = {44},
year = {2012}
}
@article{Haswell2009,
abstract = {Children with autism spectrum disorder (ASD) have deficits in motor control, imitation and social function. Does a dysfunction in the neural basis of representing internal models of action contribute to these problems? We measured patterns of generalization as children learned to control a novel tool and found that the autistic brain built a stronger than normal association between self-generated motor commands and proprioceptive feedback; furthermore, the greater the reliance on proprioception, the greater the child's impairments in social function and imitation.},
author = {Haswell, Courtney C. and Izawa, Jun and {R Dowell}, Lauren and {H Mostofsky}, Stewart and Shadmehr, Reza},
doi = {10.1038/nn.2356},
isbn = {1546-1726 (Electronic)$\backslash$n1097-6256 (Linking)},
issn = {10976256},
journal = {Nature Neuroscience},
number = {8},
pages = {970--972},
pmid = {19578379},
publisher = {Nature Publishing Group},
title = {{Representation of internal models of action in the autistic brain}},
url = {http://dx.doi.org/10.1038/nn.2356},
volume = {12},
year = {2009}
}
@article{Gaveau2014,
abstract = {The processes underlying short-term plasticity induced by visuomotor adaptation to a shifted visual field are still debated. Two main sources of error can induce motor adaptation: reaching feedback errors, which correspond to visually perceived discrepancies between hand and target positions, and errors between predicted and actual visual reafferences of the moving hand. These two sources of error are closely intertwined and difficult to disentangle, as both the target and the reaching limb are simultaneously visible. Accordingly, the goal of the present study was to clarify the relative contributions of these two types of errors during a pointing task under prism-displaced vision. In "terminal feedback error" condition, viewing of their hand by subjects was allowed only at movement end, simultaneously with viewing of the target. In "movement prediction error" condition, viewing of the hand was limited to movement duration, in the absence of any visual target, and error signals arose solely from comparisons between predicted and actual reafferences of the hand. In order to prevent intentional corrections of errors, a subthreshold, progressive stepwise increase in prism deviation was used, so that subjects remained unaware of the visual deviation applied in both conditions. An adaptive aftereffect was observed in the "terminal feedback error" condition only. As far as subjects remained unaware of the optical deviation and self-assigned pointing errors, prediction error alone was insufficient to induce adaptation. These results indicate a critical role of hand-to-target feedback error signals in visuomotor adaptation; consistent with recent neurophysiological findings, they suggest that a combination of feedback and prediction error signals is necessary for eliciting aftereffects. They also suggest that feedback error updates the prediction of reafferences when a visual perturbation is introduced gradually and cognitive factors are eliminated or strongly attenuated.},
author = {Gaveau, Val{\~{A}}{\textcopyright}rie and Prablanc, Claude and Laurent, Damien and Rossetti, Yves and Priot, Anne-Emmanuelle},
doi = {10.3389/fnhum.2014.00880},
issn = {1662-5161},
journal = {Frontiers in Human Neuroscience},
keywords = {eye-hand coordination,eye-hand coordination, visuomotor adaptation, pris,feedback error,internal model,prediction error,prism adaptation,unawareness,visuomotor adaptation},
number = {November},
pages = {1--15},
pmid = {25408644},
title = {{Visuomotor adaptation needs a validation of prediction error by feedback error}},
url = {http://journal.frontiersin.org/article/10.3389/fnhum.2014.00880/abstract},
volume = {8},
year = {2014}
}
@article{Haruno2001,
abstract = {Humans demonstrate a remarkable ability to generate accurate and appropriate motor behavior under many different and often uncertain environmental conditions. We previously proposed a new modular architecture, the modular selection and identification for control (MOSAIC) model, for motor learning and control based on multiple pairs of forward (predictor) and inverse (controller) models. The architecture simultaneously learns the multiple inverse models necessary for control as well as how to select the set of inverse models appropriate for a given environment. It combines both feedforward and feedback sensorimotor information so that the controllers can be selected both prior to movement and subsequently during movement. This article extends and evaluates the MOSAIC architecture in the following respects. The learning in the architecture was implemented by both the original gradient-descent method and the expectation-maximization (EM) algorithm. Unlike gradient descent, the newly derived EM algorithm is robust to the initial starting conditions and learning parameters. Second, simulations of an object manipulation task prove that the architecture can learn to manipulate multiple objects and switch between them appropriately. Moreover, after learning, the model shows generalization to novel objects whose dynamics lie within the polyhedra of already learned dynamics. Finally, when each of the dynamics is associated with a particular object shape, the model is able to select the appropriate controller before movement execution. When presented with a novel shape-dynamic pairing, inappropriate activation of modules is observed followed by on-line correction.},
author = {Haruno, Masahiko and Wolpert, Daniel M. and Kawato, Mitsuo},
doi = {10.1162/089976601750541778},
isbn = {10.1162/089976601750541778},
issn = {0899-7667},
journal = {Neural Computation},
number = {10},
pages = {2201--2220},
pmid = {11570996},
title = {{MOSAIC Model for Sensorimotor Learning and Control}},
url = {http://www.mitpressjournals.org/doi/10.1162/089976601750541778},
volume = {13},
year = {2001}
}
@article{Manivannan2012,
abstract = {The interconnection between vision and somatosensation is already well-established and is further supplemented by the evolutionary link between eyes and photoreceptors, and the functional connection between photosensation and thermoreception. However, our analysis shows that the relation between vision and somatosensation is much deeper and suggests that somatosensation may possibly be the basis of vision. Surprisingly, our photoreceptor itself needs somatosensory proteins for its functioning, and our entire visual pathway depends on somatosensory cues for its functioning.},
author = {Manivannan, M. and Suresh, Pawan Kumar},
doi = {10.5214/ans.0972.7531.180409},
issn = {09727531},
journal = {Annals of Neurosciences},
keywords = {Degenerins,Mechanoreception,Nociception,Photoreception,Proprioception,Thermoreception,Trek,Trekk,Trp channels},
number = {1},
pages = {31--39},
pmid = {25205961},
title = {{On the somatosensation of vision}},
volume = {19},
year = {2012}
}
@article{Mattar2013,
abstract = {A complex interplay has been demonstrated between motor and sensory systems. We showed recently that motor learning leads to changes in the sensed position of the limb (Ostry DJ, Darainy M, Mattar AA, Wong J, Gribble PL. J Neurosci 30: 5384-5393, 2010). Here, we document further the links between motor learning and changes in somatosensory perception. To study motor learning, we used a force field paradigm in which subjects learn to compensate for forces applied to the hand by a robotic device. We used a task in which subjects judge lateral displacements of the hand to study somatosensory perception. In a first experiment, we divided the motor learning task into incremental phases and tracked sensory perception throughout. We found that changes in perception occurred at a slower rate than changes in motor performance. A second experiment tested whether awareness of the motor learning process is necessary for perceptual change. In this experiment, subjects were exposed to a force field that grew gradually in strength. We found that the shift in sensory perception occurred even when awareness of motor learning was reduced. These experiments argue for a link between motor learning and changes in somatosensory perception, and they are consistent with the idea that motor learning drives sensory change.},
author = {Mattar, A. A. G. and Darainy, M. and Ostry, D. J.},
doi = {10.1152/jn.00734.2011},
isbn = {1522-1598 (Electronic)$\backslash$n0022-3077 (Linking)},
issn = {0022-3077},
journal = {Journal of Neurophysiology},
number = {3},
pages = {782--791},
pmid = {23136347},
title = {{Motor learning and its sensory effects: time course of perceptual change and its presence with gradual introduction of load}},
url = {http://jn.physiology.org/cgi/doi/10.1152/jn.00734.2011},
volume = {109},
year = {2013}
}
@article{Lindner2005,
abstract = {Psychopathological symptoms in schizophrenia patients suggest that the concept of self might be disturbed in these individuals [1]. Delusions of influence make them feel that someone else is guiding their actions, and certain kinds of their hallucinations seem to be misinterpretations of their own inner voice as an external voice, the common denominator being that self-produced information is perceived as if coming from outside. If this interpretation were correct, we might expect that schizophrenia patients might also attribute the sensory consequences of their own eye movements to the environment rather than to themselves, challenging the percept of a stable world. Indeed, this seems to be the case because we found a clear correlation between the strength of delusions of influence and the ability of schizophrenia patients to cancel out such self-induced retinal information in motion perception. This correlation reflects direct experimental evidence supporting the view that delusions of influence in schizophrenia might be due to a specific deficit in the perceptual compensation of the sensory consequences of one's own actions [1-6]. {\textcopyright}2005 Elsevier Ltd. All rights reserved.},
author = {Lindner, Axel and Thier, Peter and Kircher, Tilo T J and Haarmeier, Thomas and Leube, Dirk T.},
doi = {10.1016/j.cub.2005.05.049},
isbn = {0960-9822 (Print)},
issn = {09609822},
journal = {Current Biology},
number = {12},
pages = {1119--1124},
pmid = {15964277},
title = {{Disorders of agency in schizophrenia correlate with an inability to compensate for the sensory consequences of actions}},
volume = {15},
year = {2005}
}
@article{Lindner2005a,
abstract = {Psychopathological symptoms in schizophrenia patients suggest that the concept of self might be disturbed in these individuals [1]. Delusions of influence make them feel that someone else is guiding their actions, and certain kinds of their hallucinations seem to be misinterpretations of their own inner voice as an external voice, the common denominator being that self-produced information is perceived as if coming from outside. If this interpretation were correct, we might expect that schizophrenia patients might also attribute the sensory consequences of their own eye movements to the environment rather than to themselves, challenging the percept of a stable world. Indeed, this seems to be the case because we found a clear correlation between the strength of delusions of influence and the ability of schizophrenia patients to cancel out such self-induced retinal information in motion perception. This correlation reflects direct experimental evidence supporting the view that delusions of influence in schizophrenia might be due to a specific deficit in the perceptual compensation of the sensory consequences of one's own actions [1-6]. {\textcopyright}2005 Elsevier Ltd. All rights reserved.},
author = {Lindner, Axel and Thier, Peter and Kircher, Tilo T J and Haarmeier, Thomas and Leube, Dirk T.},
doi = {10.1016/j.cub.2005.05.049},
isbn = {0960-9822 (Print)},
issn = {09609822},
journal = {Current Biology},
number = {12},
pages = {1119--1124},
pmid = {15964277},
title = {{Disorders of agency in schizophrenia correlate with an inability to compensate for the sensory consequences of actions}},
volume = {15},
year = {2005}
}
@article{Mostafa2014,
abstract = {Studies have shown that adapting one's reaches in one location in the workspace can generalize to other novel locations. Generalization of this visuomotor adaptation is influenced by the location of novel targets relative to the trained location such that reaches made to novel targets that are located far from the trained target direction (i.e., {\~{}}22.5°; Krakauer et al. in J Neurosci 20:8916-8924, 2000) show very little generalization compared to those that are closer to the trained direction. However, generalization is much broader when reaching to novel targets in the same direction but at different distances from the trained target. In this study, we investigated whether changes in hand proprioception (proprioceptive recalibration), like reach adaptation, generalize to different distances of the workspace. Subjects adapted their reaches with a rotated cursor to two target locations at a distance of 13 cm from the home position. We then compared changes in open-loop reaches and felt hand position at these trained locations to novel targets located in the same direction as the trained targets but either at a closer (10 cm) or at a farther distance (15 cm) from the home position. We found reach adaptation generalized to novel closer and farther targets to the same extent as observed at the trained target distance. In contrast, while changes in felt hand position were significant across the two novel distances, this recalibration was smaller for the novel-far locations compared to the trained location. Given that reach adaptation completely generalized across the novel distances but proprioceptive recalibration generalized to a lesser extent for farther distances, we suggest that proprioceptive recalibration may arise independently of motor adaptation and vice versa.},
author = {Mostafa, Ahmed A. and Kamran-Disfani, Rozbeh and Bahari-Kashani, Golsa and Cressman, Erin K. and Henriques, Denise Y P},
doi = {10.1007/s00221-014-4157-9},
isbn = {1432-1106 (Electronic)$\backslash$r0014-4819 (Linking)},
issn = {14321106},
journal = {Experimental Brain Research},
keywords = {Generalization,Hand proprioception,Motor learning,Reaching,Sensory plasticity,Visuomotor adaptation},
number = {3},
pages = {817--827},
pmid = {25479737},
title = {{Generalization of reach adaptation and proprioceptive recalibration at different distances in the workspace}},
volume = {233},
year = {2014}
}
@article{Mostafa2014a,
abstract = {Reaching with visual feedback that is misaligned with respect to the actual hand's location leads to changes in reach trajectories (i.e., visuomotor adaptation). Previous studies have also demonstrated that when training to reach with misaligned visual feedback of the hand, the opposite hand also partially adapts, providing evidence of intermanual transfer. Moreover, our laboratory has shown that visuomotor adaptation to a misaligned hand cursor, either translated or rotated relative to the hand, also leads to changes in felt hand position (what we call proprioceptive recalibration), such that subjects' estimate of felt hand position relative to both visual and non-visual reference markers (e.g., body midline) shifts in the direction of the visuomotor distortion. In the present study, we first determined the extent that motor adaptation to a translated cursor leads to transfer to the opposite hand, and whether this transfer differs across the dominant and non-dominant hands. Second, we looked to establish whether changes in hand proprioception that occur with the trained hand following adaptation also transfer to the untrained hand. We found intermanual motor transfer to the left untrained (non-dominant) hand after subjects trained their right (dominant) hand to reach with translated visual feedback of their hand. Motor transfer from the left trained to the right untrained hand was not observed. Despite finding changes in felt hand position in both trained hands, we did not find similar evidence of proprioceptive recalibration in the right or left untrained hands. Taken together, our results suggest that unlike visuomotor adaptation, proprioceptive recalibration does not transfer between hands and is specific only to the arm exposed to the distortion.},
author = {Mostafa, Ahmed A. and Salomonczyk, Danielle and Cressman, Erin K. and Henriques, Denise Y.P.},
doi = {10.1007/s00221-014-3833-0},
isbn = {0022101438},
issn = {14321106},
journal = {Experimental Brain Research},
keywords = {Intermanual transfer,Learning,Proprioception,Reaching,Sensory recalibration,Visuomotor adaptation},
number = {6},
pages = {1639--1651},
pmid = {24468724},
title = {{Intermanual transfer and proprioceptive recalibration following training with translated visual feedback of the hand}},
volume = {232},
year = {2014}
}
@article{McLaughlin1967,
abstract = {During a change-of-fixation eye movement, the target toward which S was shifting his gaze was displaced 1° toward the original point of fixation so that the eye made an overshoot with respect to the new target position. When this was repeated several times in succession, the eye movement control system made an adjustment such that the overshoot gradually diminished. Ihe end-result of this “parametric adjustment” was that a visual target 10° from the fovea elicited an eye movement of only 9.1°.},
author = {McLaughlin, Samuel C.},
doi = {10.3758/BF03210071},
isbn = {1943-3921},
issn = {00315117},
journal = {Perception {\&} Psychophysics},
number = {8},
pages = {359--362},
title = {{Parametric adjustment in saccadic eye movements}},
volume = {2},
year = {1967}
}
@article{Miall2007,
abstract = {The cerebellum has been proposed to be a crucial component in the state estimation process that combines information from motor efferent and sensory afferent signals to produce a representation of the current state of the motor system. Such a state estimate of the moving human arm would be expected to be used when the arm is rapidly and skillfully reaching to a target. We now report the effects of transcranial magnetic stimulation (TMS) over the ipsilateral cerebellum as healthy humans were made to interrupt a slow voluntary movement to rapidly reach towards a visually defined target. Errors in the initial direction and in the final finger position of this reach-to-target movement were significantly higher for cerebellar stimulation than they were in control conditions. The average directional errors in the cerebellar TMS condition were consistent with the reaching movements being planned and initiated from an estimated hand position that was 138 ms out of date. We suggest that these results demonstrate that the cerebellum is responsible for estimating the hand position over this time interval and that TMS disrupts this state estimate.},
author = {Miall, R. Chris and Christensen, Lars O D and Cain, Owen and Stanley, James},
doi = {10.1371/journal.pbio.0050316},
isbn = {e316},
issn = {15449173},
journal = {PLoS Biology},
number = {11},
pages = {2733--2744},
pmid = {18044990},
title = {{Disruption of state estimation in the human lateral cerebellum}},
volume = {5},
year = {2007}
}
@article{Rumelhart1992,
abstract = {Internal models of the environment have an important role to play in adaptive systems, in general, and are of particular importance for the supervised learning paradigm. In this article we demonstrate that certain classical problems associated with the notion of the "teacher" in supervised learning can be solved by judicious use of learned internal models as components of the adaptive system. In particular, we show how supervised learning algorithms can be utilized in cases in which an unknown dynamical system intervenes between actions and desired outcomes. Our approach applies to any supervised learning algorithm that is capable of learning in multilayer networks. {\{}{\textcopyright}{\}} 1992.},
author = {Rumelhart, M Jordan and D},
doi = {DOI 10.1207/s15516709cog1603_1},
issn = {03640213},
journal = {Cognitive Science},
number = {3},
pages = {307--354},
pmid = {1000106121},
title = {{Forward Models: Supervised Learning with a Digital Teacher}},
volume = {16},
year = {1992}
}
@article{Jordan1999,
abstract = {Munc18-1 and Syntaxin1 are essential proteins for SNARE-mediated neurotransmission. Munc18-1 participates in synaptic vesicle fusion via dual roles: as a docking/chaperone protein by binding closed Syntaxin1, and as a fusion protein that binds SNARE complexes in a Syntaxin1 N-peptide dependent manner. The two roles are associated with a closed-open Syntaxin1 conformational transition. Here, we show that Syntaxin N-peptide binding to Munc18-1 is not highly selective, suggesting that other parts of the SNARE complex are involved in binding to Munc18-1. We also find that Syntaxin1, with an N peptide and a physically anchored C terminus, binds to Munc18-1 and that this complex can participate in SNARE complex formation. We report a Munc18-1-N-peptide crystal structure that, together with other data, reveals how Munc18-1 might transit from a conformation that binds closed Syntaxin1 to one that may be compatible with binding open Syntaxin1 and SNARE complexes. Our results suggest the possibility that structural transitions occur in both Munc18-1 and Syntaxin1 during their binary interaction. We hypothesize that Munc18-1 domain 3a undergoes a conformational change that may allow coiled-coil interactions with SNARE complexes.},
author = {Jordan, Michael I and Wolpert, Daniel M},
doi = {10.1073/pnas.0914906108},
isbn = {0262072548},
issn = {10916490},
journal = {The Cognitive Neurosciences},
pages = {597--609},
pmid = {21193638},
title = {{Computational motor control}},
volume = {601},
year = {1999}
}
@article{Lackner2005,
abstract = {Dynamic perturbations of reaching movements are an important technique for studying motor learning and adaptation. Adaptation to non-contacting, velocity-dependent inertial Coriolis forces generated by arm movements during passive body rotation is very rapid, and when complete the Coriolis forces are no longer sensed. Adaptation to velocity-dependent forces delivered by a robotic manipulandum takes longer and the perturbations continue to be perceived even when adaptation is complete. These differences reflect adaptive self-calibration of motor control versus learning the behavior of an external object or 'tool'. Velocity-dependent inertial Coriolis forces also arise in everyday behavior during voluntary turn and reach movements but because of anticipatory feedforward motor compensations do not affect movement accuracy despite being larger than the velocity-dependent forces typically used in experimental studies. Progress has been made in understanding: the common features that determine adaptive responses to velocity-dependent perturbations of jaw and limb movements; the transfer of adaptation to mechanical perturbations across different contact sites on a limb; and the parcellation and separate representation of the static and dynamic components of multiforce perturbations. {\textcopyright} 2005 Elsevier Ltd. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {154},
author = {Lackner, James R. and DiZio, Paul},
doi = {10.1016/j.conb.2005.10.012},
eprint = {154},
isbn = {0959-4388 (Print)$\backslash$n0959-4388 (Linking)},
issn = {09594388},
journal = {Current Opinion in Neurobiology},
number = {6},
pages = {653--659},
pmid = {16271464},
title = {{Motor control and learning in altered dynamic environments}},
volume = {15},
year = {2005}
}
@article{Jones2010a,
abstract = {The present study examined the accuracy of proprioceptive localization of the hand using two paradigms. In our proprioceptive estimation paradigm, participants judged the position of a target hand relative to visual references, or their body's midline. Placement of the target hand was active (participants pushed a robot manipulandum along a constrained path) or passive (the robot manipulandum positioned participants' target hand). In our proprioceptive-guided reaching paradigm, participants reached to the unseen location of a hand; both the left and right hands served as the target hand and the reaching hand. In both paradigms, subjects were relatively good at estimating the location of each hand (i.e. relative to a reference marker or using a reach), with directional errors falling within 2 cm of the actual target location, and little variation across the workspace. In our proprioceptive estimation paradigm, biases when the target hand was passively placed were no larger than those made when the target hand was actively placed. Participants perceived their left hand to be more to the left than it actually was, and their right hand to be more rightward than it actually was, but with a similar error magnitude across target hands. In our reaching paradigm, participants' estimates of left hand location were deviated more leftwards than their estimates of right hand location, but showed a small but similar pattern of location-dependent reach errors across the two hands. Precision of estimates did not differ between the two hands or vary with target location for either paradigm.},
author = {Jones, Stephanie A H and Cressman, Erin K. and Henriques, Denise Y P},
doi = {10.1007/s00221-009-2079-8},
isbn = {0022100920798},
issn = {00144819},
journal = {Experimental Brain Research},
keywords = {Active,Left hand,Passive,Reach,Relative judgment,Right hand},
number = {3},
pages = {373--383},
pmid = {19921158},
title = {{Proprioceptive localization of the left and right hands}},
volume = {204},
year = {2010}
}
@article{Jones2012a,
abstract = {We examine whether the task goal affects the accuracy and precision with which participants can localize an unseen hand. Proprioceptive localization was measured using three different tasks: two goal-directed movement tasks (reaching to and reproducing final hand-target location) and a perceptual estimation task in which participants judged the location of the hand-target relative to visual references. We also assessed whether proprioceptive localization in these different tasks is affected by localization from memory, the hand-target being localized (left or right) or the movement path of the proprioceptive target (9 paths, derived from combinations of starting and final hand-target positions). We found that participants were less precise when reaching from memory, but not when reproducing or estimating remembered final hand-target location. Participants also misperceived the felt location of their hands, judging their left hand to be more leftward and their right hand to be more rightward when reaching to and when estimating final hand-target location, but not when reproducing hand-target location. The movement path of the proprioceptive target did not affect localization, regardless of the task goal. Overall, localization seems poorer when proprioception is used to guide a reach with the opposite hand, particularly from memory, and best when merely reproducing the proprioceptive target site. This may have an important application in neuro-rehabilitation, whereby one task may better establish or re-establish important or failing sensory connections. {\textcopyright} 2012 Elsevier Ltd.},
author = {Jones, Stephanie A H and Fiehler, Katja and Henriques, Denise Y P},
doi = {10.1016/j.neuropsychologia.2012.02.031},
isbn = {1873-3514 (Electronic)$\backslash$r0028-3932 (Linking)},
issn = {00283932},
journal = {Neuropsychologia},
keywords = {Hand-target,Movement path,Proprioceptive localization,Proprioceptive memory,Reaching-hand},
number = {7},
pages = {1462--1470},
pmid = {22406556},
publisher = {Elsevier Ltd},
title = {{A task-dependent effect of memory and hand-target on proprioceptive localization}},
url = {http://dx.doi.org/10.1016/j.neuropsychologia.2012.02.031},
volume = {50},
year = {2012}
}
@article{Lalazar2008,
abstract = {The neural basis of the internal models used in sensorimotor transformations is beginning to be uncovered. Sensorimotor learning involves the modification of such models. Different stages of sensory-motor processing have been explored with a continuum of experimental tasks, from learning arbitrary associations of sensory cues to movements, to adapting to altered kinematic and dynamic environments. Several groups have been studying changes in neuronal activity in cortical and subcortical areas that may be related to the acquisition and consolidation processes. We discuss the progress and challenges in understanding how these learning-related neural changes are involved in the modification of internal models, and offer future directions. {\textcopyright} 2008 Elsevier Ltd. All rights reserved.},
author = {Lalazar, Hagai and Vaadia, Eilon},
doi = {10.1016/j.conb.2008.11.003},
isbn = {1873-6882 (Electronic)$\backslash$n0959-4388 (Linking)},
issn = {09594388},
journal = {Current Opinion in Neurobiology},
number = {6},
pages = {573--581},
pmid = {19054663},
title = {{Neural basis of sensorimotor learning: modifying internal models}},
volume = {18},
year = {2008}
}
@article{Kording2004,
abstract = {When we learn a new motor skill, such as playing an approaching tennis ball, both our sensors and the task possess variability. Our sensors provide imperfect information about the ball's velocity, so we can only estimate it. Combining information from multiple modalities can reduce the error in this estimate. On a longer time scale, not all velocities are a priori equally probable, and over the course of a match there will be a probability distribution of velocities. According to bayesian theory, an optimal estimate results from combining information about the distribution of velocities-the prior-with evidence from sensory feedback. As uncertainty increases, when playing in fog or at dusk, the system should increasingly rely on prior knowledge. To use a bayesian strategy, the brain would need to represent the prior distribution and the level of uncertainty in the sensory feedback. Here we control the statistical variations of a new sensorimotor task and manipulate the uncertainty of the sensory feedback. We show that subjects internally represent both the statistical distribution of the task and their sensory uncertainty, combining them in a manner consistent with a performance-optimizing bayesian process. The central nervous system therefore employs probabilistic models during sensorimotor learning.},
author = {K{\"{o}}rding, Konrad P. and Wolpert, Daniel M.},
doi = {10.1038/nature02169},
isbn = {0028-0836},
issn = {00280836},
journal = {Nature},
number = {6971},
pages = {244--247},
pmid = {14724638},
title = {{Bayesian integration in sensorimotor learning}},
volume = {427},
year = {2004}
}
@article{Kawato1987,
abstract = {In order to control voluntary movements, the central nervous system (CNS) must solve the following three computational problems at different levels: the determination of a desired trajectory in the visual coordinates, the transformation of its coordinates to the body coordinates and the generation of motor command. Based on physiological knowledge and previous models, we propose a hierarchical neural network model which accounts for the generation of motor command. In our model the association cortex provides the motor cortex with the desired trajectory in the body coordinates, where the motor command is then calculated by means of long-loop sensory feedback. Within the spinocerebellum--magnocellular red nucleus system, an internal neural model of the dynamics of the musculoskeletal system is acquired with practice, because of the heterosynaptic plasticity, while monitoring the motor command and the results of movement. Internal feedback control with this dynamical model updates the motor command by predicting a possible error of movement. Within the cerebrocerebellum--parvocellular red nucleus system, an internal neural model of the inverse-dynamics of the musculo-skeletal system is acquired while monitoring the desired trajectory and the motor command. The inverse-dynamics model substitutes for other brain regions in the complex computation of the motor command. The dynamics and the inverse-dynamics models are realized by a parallel distributed neural network, which comprises many sub-systems computing various nonlinear transformations of input signals and a neuron with heterosynaptic plasticity (that is, changes of synaptic weights are assumed proportional to a product of two kinds of synaptic inputs). Control and learning performance of the model was investigated by computer simulation, in which a robotic manipulator was used as a controlled system, with the following results: (1) Both the dynamics and the inverse-dynamics models were acquired during control of movements. (2) As motor learning proceeded, the inverse-dynamics model gradually took the place of external feedback as the main controller. Concomitantly, overall control performance became much better. (3) Once the neural network model learned to control some movement, it could control quite different and faster movements. (4) The neural network model worked well even when only very limited information about the fundamental dynamical structure of the controlled system was available.},
author = {Kawato, M. and Furukawa, Kazunori and Suzuki, R.},
doi = {10.1007/BF00364149},
isbn = {0340-1200 (Print)},
issn = {03401200},
journal = {Biological Cybernetics},
number = {3},
pages = {169--185},
pmid = {3676355},
title = {{A hierarchical neural-network model for control and learning of voluntary movement}},
volume = {57},
year = {1987}
}
@article{Shabbott2010,
abstract = {Visuomotor adaptation is mediated by errors between intended and sensory-detected arm positions. However, it is not clear whether visual-based errors that are shown during the course of motion lead to qualitatively different or more efficient adaptation than errors shown after movement. For instance, continuous visual feedback mediates online error corrections, which may facilitate or inhibit the adaptation process. We addressed this question by manipulating the timing of visual error information and task instructions during a visuomotor adaptation task. Subjects were exposed to a visuomotor rotation, during which they received continuous visual feedback (CF) of hand position with instructions to correct or not correct online errors, or knowledge-of-results (KR), provided as a static hand-path at the end of each trial. Our results showed that all groups improved performance with practice, and that online error corrections were inconsequential to the adaptation process. However, in contrast to the CF groups, the KR group showed relatively small reductions in mean error with practice, increased inter-trial variability during rotation exposure, and more limited generalization across target distances and workspace. Further, although the KR group showed improved performance with practice, after-effects were minimal when the rotation was removed. These findings suggest that simultaneous visual and proprioceptive information is critical in altering neural representations of visuomotor maps, although delayed error information may elicit compensatory strategies to offset perturbations.},
author = {Shabbott, Britne A. and Sainburg, Robert L.},
doi = {10.1007/s00221-010-2209-3},
isbn = {1432-1106 (Electronic)$\backslash$r0014-4819 (Linking)},
issn = {00144819},
journal = {Experimental Brain Research},
keywords = {Feedback,Knowledge-of-results,Vision,Visuomotor adaptation,Visuomotor rotation},
number = {1},
pages = {75--87},
pmid = {20237773},
title = {{Learning a visuomotor rotation: Simultaneous visual and proprioceptive information is crucial for visuomotor remapping}},
volume = {203},
year = {2010}
}
@article{Shadmehr2008,
abstract = {The study of patients to infer normal brain function has a long tradition in neurology and psychology. More recently, the motor system has been subject to quantitative and computational characterization. The purpose of this review is to argue that the lesion approach and theoretical motor control can mutually inform each other. Specifically, one may identify distinct motor control processes from computational models and map them onto specific deficits in patients. Here we review some of the impairments in motor control, motor learning and higher-order motor control in patients with lesions of the corticospinal tract, the cerebellum, parietal cortex, the basal ganglia, and the medial temporal lobe. We attempt to explain some of these impairments in terms of computational ideas such as state estimation, optimization, prediction, cost, and reward. We suggest that a function of the cerebellum is system identification: to build internal models that predict sensory outcome of motor commands and correct motor commands through internal feedback. A function of the parietal cortex is state estimation: to integrate the predicted proprioceptive and visual outcomes with sensory feedback to form a belief about how the commands affected the states of the body and the environment. A function of basal ganglia is related to optimal control: learning costs and rewards associated with sensory states and estimating the "cost-to-go" during execution of a motor task. Finally, functions of the primary and the premotor cortices are related to implementing the optimal control policy by transforming beliefs about proprioceptive and visual states, respectively, into motor commands.},
author = {Shadmehr, Reza and Krakauer, John W.},
doi = {10.1007/s00221-008-1280-5},
isbn = {1432-1106 (Electronic)},
issn = {00144819},
journal = {Experimental Brain Research},
keywords = {Basal ganglia,Cerebellum,Computational models,Motor cortex,Optimal control,Parietal cortex,Reaching},
number = {3},
pages = {359--381},
pmid = {18251019},
title = {{A computational neuroanatomy for motor control}},
volume = {185},
year = {2008}
}
@article{Salomonczyk2013,
abstract = {Reaching to targets with misaligned visual feedback of the hand leads to changes in proprioceptive estimates of hand position and reach aftereffects. In such tasks, subjects are able to make use of two error signals: the discrepancy between the desired and actual movement, known as the sensorimotor error signal, and the discrepancy between visual and proprioceptive estimates of hand position, which we refer to as the cross-sensory error signal. We have recently shown that mere exposure to a sensory discrepancy in the absence of goal-directed movement (i.e. no sensorimotor error signal) is sufficient to produce similar changes in felt hand position and reach aftereffects. Here, we sought to determine the extent that this cross-sensory error signal can contribute to proprioceptive recalibration and movement aftereffects by manipulating the magnitude of this signal in the absence of volitional aiming movements. Subjects pushed their hand out along a robot-generated linear path that was gradually rotated clockwise relative to the path of a cursor. On all trials, subjects viewed a cursor that headed directly towards a remembered target while their hand moved out synchronously. After exposure to a 30° rotated hand-cursor distortion, subjects recalibrated their sense of felt hand position and adapted their reaches. However, no additional increases in recalibration or aftereffects were observed following further increases in the cross-sensory error signal (e.g. up to 70°). This is in contrast to our previous study where subjects freely reached to targets with misaligned visual hand position feedback, hence experiencing both sensorimotor and cross-sensory errors, and the distortion magnitude systematically predicted increases in proprioceptive recalibration and reach aftereffects. Given these findings, we suggest that the cross-sensory error signal results in changes to felt hand position which drive partial reach aftereffects, while larger aftereffects that are produced after visuomotor adaptation (and that vary with the size of distortion) are related to the sensorimotor error signal.},
author = {Salomonczyk, Danielle and Cressman, Erin K. and Henriques, Denise Y P},
doi = {10.1007/s00221-013-3564-7},
isbn = {0014-4819},
issn = {00144819},
journal = {Experimental Brain Research},
keywords = {Error-driven learning,Proprioception,Proprioceptive recalibration,Vision,Visuomotor adaptation},
number = {3},
pages = {313--325},
pmid = {23708802},
title = {{The role of the cross-sensory error signal in visuomotor adaptation}},
volume = {228},
year = {2013}
}
@article{Salomonczyk2012,
abstract = {Previous studies have demonstrated that after reaching with misaligned visual feedback of the hand, one adapts his or her reaches and partially recalibrates proprioception, such that sense of felt hand position is shifted to match the seen hand position. However, to date, this has only been demonstrated in the right (dominant) hand following reach training with a visuomotor distortion in which the rotated cursor distortion was introduced gradually. As reach adaptation has been shown to differ depending on how the distortion is introduced (gradual vs. abrupt), we sought to examine proprioceptive recalibration following reach training with a cursor that was abruptly rotated 30° clockwise relative to hand motion. Furthermore, because the left and right arms have demonstrated selective advantages when matching visual and proprioceptive targets, respectively, we assessed proprioceptive recalibration in right-handed subjects following training with either the right or the left hand. On average, we observed shifts in felt hand position of approximately 7.6° following training with misaligned visual feedback of the hand, which is consistent with our previous findings in which the distortion was introduced gradually. Moreover, no difference was observed in proprioceptive recalibration across the left and right hands. These findings suggest that proprioceptive recalibration is a robust process that arises symmetrically in the two hands following visuomotor adaptation regardless of the initial magnitude of the error signal.},
author = {Salomonczyk, Danielle and Henriques, Denise Y P and Cressman, Erin K.},
doi = {10.1007/s00221-011-2985-4},
isbn = {1432-1106 (Electronic)$\backslash$r0014-4819 (Linking)},
issn = {00144819},
journal = {Experimental Brain Research},
keywords = {Learning,Plasticity,Proprioception,Sensory recalibration,Vision,Visuomotor adaptation},
number = {2},
pages = {187--196},
pmid = {22198532},
title = {{Proprioceptive recalibration in the right and left hands following abrupt visuomotor adaptation}},
volume = {217},
year = {2012}
}
@article{Sperry1950,
author = {Sperry, R W},
pages = {482--489},
title = {{NEURAL BASIS OF THE SPONTANEOUS OPTOKINETIC RESPONSE PRODUCED BY VISUAL INVERSION One of the most conspicuous behavioral effects produced by surgical rotation of the eyeball through 180 degrees is the forced circling or spontaneous opto- kinetic reaction}},
year = {1950}
}
@article{Synofzik2008b,
author = {Synofzik, Matthis},
title = {{Die Rolle interner Modelle bei der Wahrnehmung von Eigenbewegungen Inaugural-Dissertation zur Erlangung des Doktorgrades der Medizin der Medizinischen Fakult{\"{a}}t der Eberhard-Karls-Universit{\"{a}}t zu T{\"{u}}bingen vorgelegt von Matthis Benjamin Synofzik aus Marburg}},
year = {2008}
}
@article{Shadmehr1994,
abstract = {We investigated how the CNS learns to control movements in different dynamical conditions, and how this learned behavior is represented. In particular, we considered the task of making reaching movements in the presence of externally imposed forces from a mechanical environment. This environment was a force field produced by a robot manipulandum, and the subjects made reaching movements while holding the end-effector of this manipulandum. Since the force field significantly changed the dynamics of the task, subjects' initial movements in the force field were grossly distorted compared to their movements in free space. However, with practice, hand trajectories in the force field converged to a path very similar to that observed in free space. This indicated that for reaching movements, there was a kinematic plan independent of dynamical conditions. The recovery of performance within the changed mechanical environment is motor adaptation. In order to investigate the mechanism underlying this adaptation, we considered the response to the sudden removal of the field after a training phase. The resulting trajectories, named aftereffects, were approximately mirror images of those that were observed when the subjects were initially exposed to the field. This suggested that the motor controller was gradually composing a model of the force field, a model that the nervous system used to predict and compensate for the forces imposed by the environment. In order to explore the structure of the model, we investigated whether adaptation to a force field, as presented in a small region, led to aftereffects in other regions of the workspace. We found that indeed there were aftereffects in workspace regions where no exposure to the field had taken place; that is, there was transfer beyond the boundary of the training data. This observation rules out the hypothesis that the subject's model of the force field was constructed as a narrow association between visited states and experienced forces; that is, adaptation was not via composition of a look-up table. In contrast, subjects modeled the force field by a combination of computational elements whose output was broadly tuned across the motor state space. These elements formed a model that extrapolated to outside the training region in a coordinate system similar to that of the joints and muscles rather than end-point forces. This geometric property suggests that the elements of the adaptive process represent dynamics of a motor task in terms of the intrinsic coordinate system of the sensors and actuators.},
author = {Shadmehr, R and Mussa-Ivaldi, F a},
doi = {8182467},
isbn = {0270-6474 (Print)$\backslash$n0270-6474 (Linking)},
issn = {0270-6474},
journal = {The Journal of Neuroscience},
number = {5},
pages = {3208--3224},
pmid = {8182467},
title = {{Adaptive representation of dynamics during learning of a motor task}},
volume = {14},
year = {1994}
}
@article{Shadmehr2010,
abstract = {Motor control is the study of how organisms make accurate goal-directed movements. Here we consider two problems that the motor system must solve in order to achieve such control. The first problem is that sensory feedback is noisy and delayed, which can make movements inaccurate and unstable. The second problem is that the relationship between a motor command and the movement it produces is variable, as the body and the environment can both change. A solution is to build adaptive internal models of the body and the world. The predictions of these internal models, called forward models because they transform motor commands into sensory consequences, can be used to both pro-duce a lifetime of calibrated movements, and to improve the ability of the sensory system to estimate the state of the body and the world around it. Forward models are only useful if they produce unbiased predictions. Evidence shows that forward models remain calibrated through motor adaptation: learning driven by sensory prediction errors.},
archivePrefix = {arXiv},
arxivId = {f},
author = {Shadmehr, Reza and Smith, Maurice A. and Krakauer, John W.},
doi = {10.1146/annurev-neuro-060909-153135},
eprint = {f},
isbn = {1545-4126 (Electronic)$\backslash$n0147-006X (Linking)},
issn = {0147-006X},
journal = {Annual Review of Neuroscience},
keywords = {error feedback,forward models,motor adaptation,reaching,saccades,sensorimotor integration},
number = {1},
pages = {89--108},
pmid = {20367317},
title = {{Error Correction, Sensory Prediction, and Adaptation in Motor Control}},
url = {http://www.annualreviews.org/doi/10.1146/annurev-neuro-060909-153135},
volume = {33},
year = {2010}
}
@article{Nourouzpour2014,
abstract = {We have recently shown that visuomotor adaptation following reaches with a misaligned cursor not only induces changes in an individual's motor output, but their proprioceptive sense of hand position as well. Long-term changes are seen in motor adaptation; however, very little is known about the retention of changes in felt hand position. We sought to evaluate whether this recalibration in proprioception, following visuomotor adaptation, is sufficiently robust to be retained the following day ({\~{}}24 h later), and if so, to determine its extent. Visuomotor adaptation was induced by having subjects perform reaches to visual targets using a cursor representing their unseen hand, which had been gradually rotated 45° counterclockwise. Motor adaptation and proprioceptive recalibration were determined by assessing subjects' reach aftereffects and changes in hand bias, respectively. We found that subjects adapted their reaches and recalibrated their sense of hand position following training with a misaligned cursor, as shown in Cressman and Henriques (J Neurophysiol 102:3505-3518, 2009). More importantly, subjects who showed proprioceptive recalibration in the direction of motor adaptation on Day 1 did retain changes in felt hand position and motor adaptation on Day 2. These findings suggest that in addition to motor changes, individuals are capable of retaining sensory changes in proprioception up to 24 h later.},
author = {Nourouzpour, Nilufer and Salomonczyk, Danielle and Cressman, Erin K. and Henriques, Denise Y P},
doi = {10.1007/s00221-014-4176-6},
isbn = {0022101441766},
issn = {14321106},
journal = {Experimental Brain Research},
keywords = {Motor learning,Proprioception,Proprioceptive recalibration,Retention,Visuomotor adaptation},
number = {3},
pages = {1019--1029},
pmid = {25537467},
title = {{Retention of proprioceptive recalibration following visuomotor adaptation}},
volume = {233},
year = {2014}
}
@article{Ostry2003,
abstract = {The ability to formulate explicit mathematical models of motor systems has played a central role in recent progress in motor control research. As a result of these modeling efforts and in particular the incorporation of concepts drawn from control systems theory, ideas about motor control have changed substantially. There is growing emphasis on motor learning and particularly on predictive or anticipatory aspects of control that are related to the neural representation of dynamics. Two ideas have become increasingly prominent in mathematical modeling of motor function--forward internal models and inverse dynamics. The notion of forward internal models which has drawn from work in adaptive control arises from the recognition that the nervous system takes account of dynamics in motion planning. Inverse dynamics, a complementary way of adjusting control signals to deal with dynamics, has proved a simple means to establish the joint torques necessary to produce desired movements. In this paper, we review the force control formulation in which inverse dynamics and forward internal models play a central role. We present evidence in its favor and describe its limitations. We note that inverse dynamics and forward models are potential solutions to general problems in motor control--how the nervous system establishes a mapping between desired movements and associated control signals, and how control signals are adjusted in the context of motor learning, dynamics and loads. However, we find little empirical evidence that specifically supports the inverse dynamics or forward internal model proposals per se. We further conclude that the central idea of the force control hypothesis--that control levels operate through the central specification of forces--is flawed. This is specifically evident in the context of attempts to incorporate physiologically realistic muscle and reflex mechanisms into the force control model. In particular, the formulation offers no means to shift between postures without triggering resistance due to postural stabilizing mechanisms.},
author = {Ostry, David J. and Feldman, Anatol G.},
doi = {10.1007/s00221-003-1624-0},
isbn = {0014-4819 (Print)$\backslash$r0014-4819 (Linking)},
issn = {00144819},
journal = {Experimental Brain Research},
keywords = {Internal models,Inverse dynamics,Posture-movement problem,Predictive mechanisms,Stability},
number = {3},
pages = {275--288},
pmid = {14610628},
title = {{A critical evaluation of the force control hypothesis in motor control}},
volume = {153},
year = {2003}
}
@article{Neva2013,
abstract = {Many studies have shown that reaching movements to visual targets can rapidly adapt to altered visual feedback of hand motion (i.e., visuomotor rotation) and generalize to new target directions. This generalization is thought to reflect the acquisition of a neural representation of the novel visuomotor environment that is localized to the particular trained direction. In these studies, participants perform movements to a small number of target locations repeatedly. However, it is unclear whether adaptation and generalization are comparable when target locations are constantly varied and participants reach to visual targets one time only. Here, we compared performance for reaches to a 30° counter-clockwise visuomotor rotation to four targets, spaced 90° apart across four areas of workspace 18 times each (repeated practice (RP)) with one time only reaching movements to 72 targets, spaced 5° apart (varied practice (VP)). For both training groups, participants performed 18 reaches to radial targets (either at the repeated or varied location) in a specific area of the workspace (i.e., one of four quadrants) before reaching in the adjacent workspace. We found that the RP group adapted more completely compared to the VP group. Conversely, the VP group generalized to new target directions more completely when reaching without cursor feedback compared to the RP group. This suggests that RP and VP follow a mainly common pattern of adaptation and generalization represented in the brain, with benefits of faster adaptation with RP and more complete generalization with VP.},
author = {Neva, Jason L. and Henriques, Denise Y.P.},
doi = {10.1007/s00221-013-3444-1},
isbn = {0014-4819},
issn = {00144819},
journal = {Experimental Brain Research},
keywords = {Generalization,Motor learning,Reaching movements,Visuomotor adaptation,Visuomotor rotation},
number = {3},
pages = {363--372},
pmid = {23455723},
title = {{Visuomotor adaptation and generalization with repeated and varied training}},
volume = {226},
year = {2013}
}
@article{Nikooyan2015,
abstract = {Recent findings have demonstrated that reward feedback alone can drive motor learning. However, it is not yet clear whether reward feedback alone can lead to learning when a perturbation is introduced abruptly, or how a reward gradient can modulate learning. Here, we provide reward feedback that decays continuously with increasing error. We asked whether it is possible to learn an abrupt visuomotor rotation by reward alone, and if the learning process could be modulated by combining reward and sensory feedback and/or by using different reward landscapes. We designed a novel visuomotor learning protocol during which subjects experienced an abruptly introduced rotational perturbation. Subjects received either visual feedback, reward feedback, or a combination of the two. Two different reward landscapes, where the reward decayed either linearly or cubically with distance from the target, were tested. Results demonstrate that it is possible to learn from reward feedback alone and that the combination of reward and sensory feedback accelerates learning. An analysis of the underlying mechanisms revealed that while reward feedback alone does not allow for sensorimotor remapping, it can nonetheless lead to broad generalization, highlighting a dissociation between remapping and generalization. Secondly, the combination of reward and sensory feedback accelerates learning without compromising sensorimotor remapping. These findings suggest that the use of reward feedback is a promising approach to either supplement or substitute sensory feedback, in the development of improved neurorehabilitation techniques. More generally, they point to an important role played by reward in the motor learning process.},
author = {Nikooyan, Ali A. and Ahmed, Alaa A.},
doi = {10.1152/jn.00032.2014},
issn = {0022-3077},
journal = {Journal of Neurophysiology},
number = {2},
pages = {633--646},
pmid = {25355957},
title = {{Reward feedback accelerates motor learning}},
url = {http://jn.physiology.org/lookup/doi/10.1152/jn.00032.2014},
volume = {113},
year = {2015}
}
@article{Rhodes2015,
author = {Rhodes, D. and Woodgate, P. J. W.},
doi = {10.1523/JNEUROSCI.4243-14.2015},
issn = {0270-6474},
journal = {Journal of Neuroscience},
number = {2},
pages = {439--441},
pmid = {25589739},
title = {{Guidance of Movements by Prior Experience: A Bayesian Account of Reach Performance}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.4243-14.2015},
volume = {35},
year = {2015}
}
@article{Salomonczyk2011,
abstract = {Reaching with misaligned visual feedback of the hand leads to reach adaptation (motor recalibration) and also results in partial sensory recalibration, where proprioceptive estimates of hand position are changed in a way that is consistent with the visual distortion. The goal of the present study was to explore the relationship between changes in sensory and motor systems by examining these processes following (1) prolonged reach training and (2) training with increasing visuomotor distortions. To examine proprioceptive recalibration, we determined the position at which subjects felt their hand was aligned with a reference marker after completing three blocks of reach training trials with a cursor that was rotated 30° clockwise (CW) for all blocks, or with a visuomotor distortion that was increased incrementally across the training blocks up to 70° CW relative to actual hand motion. On average, subjects adapted their reaches by 16° and recalibrated their sense of felt hand position by 7° leftwards following the first block of reach training trials in which they reached with a cursor that was rotated 30° CW relative to the hand, compared to baseline values. There was no change in these values for the 30° training group across subsequent training blocks. However, subjects training with increasing levels of visuomotor distortion showed increased reach adaptation (up to 34° leftward movement aftereffects) and sensory recalibration (up to 15° leftwards). Analysis of motor and sensory changes following each training block did not reveal any significant correlations, suggesting that the processes underlying motor adaptation and proprioceptive recalibration occur simultaneously yet independently of each other. {\textcopyright} 2011 Elsevier Ltd.},
author = {Salomonczyk, Danielle and Cressman, Erin K. and Henriques, Denise Y P},
doi = {10.1016/j.neuropsychologia.2011.07.006},
isbn = {1873-3514 (Electronic)$\backslash$n0028-3932 (Linking)},
issn = {00283932},
journal = {Neuropsychologia},
keywords = {Arm,Motor control,Motor learning,Proprioception,Visuomotor adaptation},
number = {11},
pages = {3053--3062},
pmid = {21787794},
publisher = {Elsevier Ltd},
title = {{Proprioceptive recalibration following prolonged training and increasing distortions in visuomotor adaptation}},
url = {http://dx.doi.org/10.1016/j.neuropsychologia.2011.07.006},
volume = {49},
year = {2011}
}
@article{Ostry2010,
abstract = {Motor learning is dependent upon plasticity in motor areas of the brain, but does it occur in isolation, or does it also result in changes to sensory systems? We examined changes to somatosensory function that occur in conjunction with motor learning. We found that even after periods of training as brief as 10 min, sensed limb position was altered and the perceptual change persisted for 24 h. The perceptual change was reflected in subsequent movements; limb movements following learning deviated from the prelearning trajectory by an amount that was not different in magnitude and in the same direction as the perceptual shift. Crucially, the perceptual change was dependent upon motor learning. When the limb was displaced passively such that subjects experienced similar kinematics but without learning, no sensory change was observed. The findings indicate that motor learning affects not only motor areas of the brain but changes sensory function as well.},
author = {Ostry, D. J. and Darainy, M. and Mattar, A. A. G. and Wong, J. and Gribble, P. L.},
doi = {10.1523/JNEUROSCI.4571-09.2010},
isbn = {1529-2401 (Electronic) 0270-6474 (Linking)},
issn = {0270-6474},
journal = {Journal of Neuroscience},
number = {15},
pages = {5384--5393},
pmid = {20392960},
title = {{Somatosensory Plasticity and Motor Learning}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.4571-09.2010},
volume = {30},
year = {2010}
}
@article{Proske2012,
abstract = {This is a review of the proprioceptive senses generated as a result of our own actions. They include the senses of position and movement of our limbs and trunk, the sense of effort, the sense of force, and the sense of heaviness. Receptors involved in proprioception are located in skin, muscles, and joints. Information about limb position and movement is not generated by individual receptors, but by populations of afferents. Afferent signals generated during a movement are processed to code for endpoint position of a limb. The afferent input is referred to a central body map to determine the location of the limbs in space. Experimental phantom limbs, produced by blocking peripheral nerves, have shown that motor areas in the brain are able to generate conscious sensations of limb displacement and movement in the absence of any sensory input. In the normal limb tendon organs and possibly also muscle spindles contribute to the senses of force and heaviness. Exercise can disturb proprioception, and this has implications for musculoskeletal injuries. Proprioceptive senses, particularly of limb position and movement, deteriorate with age and are associated with an increased risk of falls in the elderly. The more recent information available on proprioception has given a better understanding of the mechanisms underlying these senses as well as providing new insight into a range of clinical conditions.},
author = {Proske, U. and Gandevia, S. C.},
doi = {10.1152/physrev.00048.2011},
isbn = {1522-1210; 0031-9333},
issn = {0031-9333},
journal = {Physiological Reviews},
number = {4},
pages = {1651--1697},
pmid = {23073629},
title = {{The Proprioceptive Senses: Their Roles in Signaling Body Shape, Body Position and Movement, and Muscle Force}},
url = {http://physrev.physiology.org/cgi/doi/10.1152/physrev.00048.2011},
volume = {92},
year = {2012}
}
@article{VanBeers1999,
abstract = {In a previous study we investigated how the CNS combines simultaneous visual and proprioceptive information about the position of the finger. We found that localization of the index finger of a seen hand was more precise (a smaller variance) than could reasonably be expected from the precision of localization on the basis of vision only and proprioception only. This suggests that, in localizing the tip of the index finger of a seen hand, the CNS may make use of more information than proprioceptive information and visual information about the fingertip. In the present study we investigate whether this additional information stems from additional sources of sensory information. In experiment 1 we tested whether seeing an entire arm instead of only the fingertip gives rise to a more precise proprioceptive and/or visual localization of that fingertip. In experiment 2 we checked whether the presence of a structured visual environment leads to a more precise proprioceptive localization of the index finger of an unseen hand. In experiment 3 we investigated whether looking in the direction of the index finger of an unseen hand improves proprioceptive localization of that finger. We found no significant effect in any of the experiments. The results refute the hypothesis that the investigated effects can explain the previously reported very precise localization of a seen hand. This suggests that localization of a seen finger is based exclusively on proprioception and on vision of the finger. The results suggest that these sensory signals may contain more information than is described by the magnitude of their variances.},
author = {{Van Beers}, Robert J. and Sittig, Anne C. and {Denier Van Der Gon}, Jan J.},
doi = {10.1007/s002210050656},
isbn = {0014-4819},
issn = {00144819},
journal = {Experimental Brain Research},
keywords = {Human,Multisensory integration,Proprioception,Visual context,Visual localization},
number = {1},
pages = {43--49},
pmid = {10100975},
title = {{Localization of a seen finger is based exclusively on proprioception and on vision of the finger}},
volume = {125},
year = {1999}
}
@article{Robert1999,
author = {Robert, J and Sittig, Anne C and Denier, J A N J},
journal = {Integration The Vlsi Journal},
pages = {1355--1364},
title = {{An Experimentally Supported Model}},
year = {1999}
}
@article{VanBeers1996,
abstract = {To enable us to study how humans combine simultaneously present visual and proprioceptive position information, we had subjects perform a matching task. Seated at a table, they placed their left hand under the table concealing it from their gaze. They then had to match the proprioceptively perceived position of the left hand using only proprioceptive, only visual or both proprioceptive and visual information. We analysed the variance of the indicated positions in the various conditions. We compared the results with the predictions of a model in which simultaneously present visual and proprioceptive position information about the same object is integrated in the most effective way. The results are in disagreement with the model: the variance of the condition with both visual and proprioceptive information is smaller than expected from the variances of the other conditions. This means that the available information was integrated in a highly effective way. Furthermore, the results suggest that additional information was used. This information might have been visual information about body parts other than the fingertip or it might have been visual information about the environment.},
author = {{Van Beers}, Robert J. and Sittig, Anne C. and {Denier Van Der Gon}, Jan J.},
doi = {10.1007/BF00227302},
isbn = {0014-4819},
issn = {00144819},
journal = {Experimental Brain Research},
keywords = {Human,Multisensory integration,Proprioception,Slow movement,Spatial localisation},
number = {2},
pages = {253--261},
pmid = {8891655},
title = {{How humans combine simultaneous proprioceptive and visual position information}},
volume = {111},
year = {1996}
}
@article{VanBeers1998,
abstract = {The purpose of this study was to determine the precision of proprioceptive localization of the hand in humans. We derived spatial probability distributions which describe the precision of localization on the basis of three different sources of information: proprioceptive information about the left hand, proprioceptive information about the right hand, and visual information. In the experiment subjects were seated at a table and had to perform three different position-matching tasks. In each task, the position of a target and the position of an indicator were available in a different combination of two of these three sources of information. From the spatial distributions of indicated positions in these three conditions, we derived spatial probability distributions for proprioceptive localization of the two hands and for visual localization. For proprioception we found that localization in the radial direction with respect to the shoulder is more precise than localization in the azimuthal direction. The distributions for proprioceptive localization also suggest that hand positions closer to the shoulder are localized more precisely than positions further away. These patterns can be understood from the geometry of the arm. In addition, the variability in the indicated positions suggests that the shoulder and elbow angles are known to the central nervous system with a precision of 0.6-1.1 degrees. This is a considerably better precision than the values reported in studies on perception of these angles. This implies that joint angles, or quantities equivalent to them, are represented in the central nervous system more precisely than they are consciously perceived. For visual localization we found that localization in the azimuthal direction with respect to the cyclopean eye is more precise than localization in the radial direction. The precision of the perception of visual direction is of the order of 0.2-0.6 degrees.},
author = {{Van Beers}, Robert J. and Sittig, Anne C. and {Denier Van Der Gon}, Jan J.},
doi = {10.1007/s002210050525},
isbn = {0014-4819 (Print)$\backslash$r0014-4819 (Linking)},
issn = {00144819},
journal = {Experimental Brain Research},
keywords = {Hand position sense,Human,Joint angle,Proprioception,Visual localization},
number = {4},
pages = {367--377},
pmid = {9827856},
title = {{The precision of proprioceptive position sense}},
volume = {122},
year = {1998}
}
@article{VonHolst1950,
abstract = {Title translation: "The Reafference Principle: Interactions between the Central Nervous System and Periphery"},
author = {von Holst, Erich and Mittelstaedt, Horst},
doi = {10.1007/BF00622503},
isbn = {0028-1042},
issn = {00281042},
journal = {Die Naturwissenschaften},
number = {20},
pages = {464--476},
title = {{Das Reafferenzprinzip - Wechselwirkungen zwischen Zentralnervensystem und Peripherie}},
volume = {37},
year = {1950}
}
@article{Wei2008,
abstract = {During motor adaptation the nervous system constantly uses error information to improve future movements. Today's mainstream models simply assume that the nervous system adapts linearly and proportionally to errors. However, not all movement errors are relevant to our own action. The environment may transiently disturb the movement production-for example, a gust of wind blows the tennis ball away from its intended trajectory. Apparently the nervous system should not adapt its motor plan in the subsequent tennis strokes based on this irrelevant movement error. We hypothesize that the nervous system estimates the relevance of each observed error and adapts strongly only to relevant errors. Here we present a Bayesian treatment of this problem. The model calculates how likely an error is relevant to the motor plant and derives an ideal adaptation strategy that leads to the most precise movements. This model predicts that adaptation should be a nonlinear function of the size of an error. In reaching experiments we found strong evidence for the predicted nonlinear strategy. The model also explains published data on saccadic gain adaptation, adaptation to visuomotor rotations, and force perturbations. Our study suggests that the nervous system constantly and effortlessly estimates the relevance of observed movement errors for successful motor adaptation.},
author = {Wei, K. and Kording, K.},
doi = {10.1152/jn.90545.2008},
isbn = {1293012939},
issn = {0022-3077},
journal = {Journal of Neurophysiology},
number = {2},
pages = {655--664},
pmid = {19019979},
title = {{Relevance of Error: What Drives Motor Adaptation?}},
url = {http://jn.physiology.org/cgi/doi/10.1152/jn.90545.2008},
volume = {101},
year = {2008}
}
@article{Beers2002,
author = {van Beers, Robert J},
number = {02},
pages = {834--837},
title = {{When Feeling Is More Important Than Seeing$\backslash$rin Sensorimotor Adaptation}},
volume = {12},
year = {2002}
}
@article{VanDerKooij2015,
abstract = {Even when provided with feedback after every movement, adaptation levels off before biases are completely removed. Incomplete adaptation has recently been attributed to forgetting: the adaptation is already partially forgotten by the time the next movement is made. Here we test whether this idea is correct. If so, the final level of adaptation is determined by a balance between learning and forgetting. Because we learn from perceived errors, scaling these errors by a magnification factor has the same effect as subjects increasing the amount by which they learn from each error. In contrast, there is no reason to expect scaling the errors to affect forgetting. The magnification factor should therefore influence the balance between learning and forgetting, and thereby the final level of adaptation. We found that adaptation was indeed more complete for larger magnification factors. This supports the idea that incomplete adaptation is caused by part of what has been learnt quickly being forgotten.},
author = {{Van Der Kooij}, Katinka and Brenner, Eli and {Van Beers}, Robert J. and Smeets, Jeroen B.J.},
doi = {10.1371/journal.pone.0117901},
issn = {19326203},
journal = {PLoS ONE},
number = {2},
pages = {1--13},
pmid = {25723763},
title = {{Visuomotor adaptation: How forgetting keeps us conservative}},
volume = {10},
year = {2015}
}
@article{Synofzik2009,
abstract = {Recent work has demonstrated that the sense of agency is not only determined by efference-copy-based internal predictions and internal comparator mechanisms, but by a large variety of different internal and external cues. The study by Moore and colleagues [Moore, J. W., Wegner, D. M., {\&} Haggard, P. (2009). Modulating the sense of agency with external cues. Conscious and Cognition] aimed to provide further evidence for this view by demonstrating that external agency cues might outweigh or even substitute efferent signals to install a basic registration of self-agency. Although the study contains some critical points that, so we argue, are central to a proper interpretation of the data, it hints at a new perspective on agency: optimal cue integration seems to be the key to a robust sense of agency. We here argue that this framework could allow integrating the findings of Moore and colleagues and other recent agency studies into a comprehensive picture of the sense of agency and its pathological disruptions. {\textcopyright} 2009 Elsevier Inc. All rights reserved.},
author = {Synofzik, Matthis and Vosgerau, Gottfried and Lindner, Axel},
doi = {10.1016/j.concog.2009.07.007},
issn = {10538100},
journal = {Consciousness and Cognition},
keywords = {Bayesian rule,Comparator model,Efference copy,Intentional binding,Internal predictions,Self-consciousness,Sense of agency},
number = {4},
pages = {1065--1068},
pmid = {19683460},
publisher = {Elsevier Inc.},
title = {{Me or not me - An optimal integration of agency cues?}},
url = {http://dx.doi.org/10.1016/j.concog.2009.07.007},
volume = {18},
year = {2009}
}
@article{Synofzik2006,
abstract = {Synofzik, Matthis, Peter Thier, and Axel Lindner. Internalizing agency of self-action: perception of one's own hand movements depends on an adaptable prediction about the sensory action outcome. Extensive work on learning in reaching and pointing tasks has demonstrated high degrees of plasticity in our ability to optimize goal-directed motor behavior. However, studies focusing on the perceptual awareness of our own actions during motor adaptation are still rare. Here we present the first simultaneous investigation of sensorimotor adaptation on both levels, i.e., action and action perception. We hypothesized that self-action perception relies on internal predictions about the sensory action outcome that are updated in a way similar to that of motor control. Twenty human subjects performed out-and-back pointing movements that were fed back visually. Feedback was initially presented in spatiotemporal correspondence with respect to the actual finger position, but later rotated by a constant angle. When distorted feedback was applied repetitively, subjects' perceived pointing direction shifted in the direction of the trajectory rotation. A comparable perceptual reinter-pretation was observed in control trials without visual feedback, indicating that subjects learned to predict the new visual outcome of their actions based on nonvisual, internal information. The perception of the world, however, remained unchanged. The changes in percep-tion of one's own movements were accompanied by adaptive changes in motor performance of the same amount, i.e., a secondary motor compensation opposite to the direction of the imposed visual rotation. Our results show that the perception of one's own actions depends on adaptable internal predictions about the sensory action outcome, allowing us to attribute new sensory consequences of our actions to our own agency. Furthermore, they indicate that the updated sensory prediction can be used to optimize motor control. I N T R O D U C T I O N An organism's behavior critically depends on correctly judg-ing the origin of afferent information as resulting from either the outside world (exafference) or from one's own actions (reafference). It is suggested that for this distinction the brain resorts to internal predictions about the expected sensory con-sequences of one's own behavior (Holst and Mittelstaedt 1950). If sensory feedback is incongruent with the expected reafference an external attribution of the causation of the sensory stimuli occurs and these sensations are accentuated (Blakemore et al. 1998a; Farrer et al. 2003; Frith 1992). If sensory events are congruent with this internal prediction, however, they are attributed to one's own agency. This is reflected, for example, by the attenuation of self-produced somatosensory stimulation whenever we touch ourselves (Bays et al. 2005; Blakemore et al. 1998b, 1999; Shergill et al. 2003). Another well-known example is the perceptual cancellation of self-induced optical flow while we perform eye movements (see, e.g., Haarmeier et al. 2001; von Helmholtz 1867). One and the same movement, however, can have different sensory consequences depending on context or changing body conditions such as fatigue, aging, or disease. How then can the brain still adequately inform perceptual evaluation? In partic-ular, how can it predict the altered reafference and attribute it to its own actions rather than to events occurring from the outside world? To account for these challenges one has to postulate a plastic mechanism for the attribution of self-agency that optimizes the predicted sensory outcome of one's own movements. Such a mechanism should align the reafferences with the respective action by constantly recalibrating sensori-motor interrelations. Elegant work in the field of prism adaptation has shown that the perception of one's movements can change as part of a global recalibration of the perception of the world (for review see Redding et al. 2005), especially under conditions of active exploration and sensorimotor adaptation (Held 1965; Held and Freedman 1963). Yet the idea of a separate perceptual recali-bration process that specifically confines to the perception of one's own movements (reafferences only) and that is not secondary to a global change in visual perception (all affer-ences) still lacks compelling empirical support, even though it may be intriguing and conceptually very useful. To provide evidence for the existence of such a mechanism, we studied the perception of one's own hand movements: we propose that the perceptual awareness of one's own hand movements is an inferential process building on a comparison between internal predictions of the upcoming sensory consequences and the actual sensory feedback. Moreover, we hypothesize that this is a highly plastic process. If the reafferent feedback about one's hand movements is constantly altered, predictions on one's sensory action outcome will be correspondingly updated. This makes the surprising prediction that sensory consequences of one's actions coming with a large, but constant spatial distor-tion will then be perceived to correspond to the action. Addi-tionally, we asked whether the internal predictions underlying},
author = {Synofzik, M.},
doi = {10.1152/jn.00104.2006},
isbn = {0022-3077 (Print)$\backslash$r0022-3077 (Linking)},
issn = {0022-3077},
journal = {Journal of Neurophysiology},
number = {3},
pages = {1592--1601},
pmid = {16738220},
title = {{Internalizing Agency of Self-Action: Perception of One's Own Hand Movements Depends on an Adaptable Prediction About the Sensory Action Outcome}},
url = {http://jn.physiology.org/cgi/doi/10.1152/jn.00104.2006},
volume = {96},
year = {2006}
}
@article{Synofzik2008c,
abstract = {There is an increasing amount of empirical work investigating the sense of agency, i.e. the registration that we are the initiators of our own actions. Many studies try to relate the sense of agency to an internal feed-forward mechanism, called the "comparator model". In this paper, we draw a sharp distinction between a non-conceptual level of feeling of agency and a conceptual level of judgement of agency. By analyzing recent empirical studies, we show that the comparator model is not able to explain either. Rather, we argue for a two-step account: a multifactorial weighting process of different agency indicators accounts for the feeling of agency, which is, in a second step, further processed by conceptual modules to form an attribution judgement. This new framework is then applied to disruptions of agency in schizophrenia, for which the comparator model also fails. Two further extensions are discussed: We show that the comparator model can neither be extended to account for the sense of ownership (which also has to be differentiated into a feeling and a judgement of ownership) nor for the sense of agency for thoughts. Our framework, however, is able to provide a unified account for the sense of agency for both actions and thoughts. {\textcopyright} 2007 Elsevier Inc. All rights reserved.},
author = {Synofzik, Matthis and Vosgerau, Gottfried and Newen, Albert},
doi = {10.1016/j.concog.2007.03.010},
isbn = {1090-2376 (Electronic)},
issn = {10538100},
journal = {Consciousness and Cognition},
keywords = {Alien hand,Delusions,Delusions of control,Efference copy,Internal model,Ownership,Schizophrenia,Self,Sense of agency,Thought insertion},
number = {1},
pages = {219--239},
pmid = {17482480},
title = {{Beyond the comparator model: A multifactorial two-step account of agency}},
volume = {17},
year = {2008}
}
@article{Synofzik2008d,
abstract = {The neurocognitive structure of the acting self has recently been widely studied, yet is still perplexing and remains an often confounded issue in cognitive neuroscience, psychopathology and philosophy. We provide a new systematic account of two of its main features, the sense of agency and the sense of ownership, demonstrating that although both features appear as phenomenally uniform, they each in fact are complex crossmodal phenomena of largely heterogeneous functional and (self-)representational levels. These levels can be arranged within a gradually evolving, onto- and phylogenetically plausible framework which proceeds from basic non-conceptual sensorimotor processes to more complex conceptual and meta-representational processes of agency and ownership, respectively. In particular, three fundamental levels of agency and ownership processing have to be distinguished: The level of feeling, thinking and social interaction. This naturalistic account will not only allow to "ground the self in action", but also provide an empirically testable taxonomy for cognitive neuroscience and a new tool for disentangling agency and ownership disturbances in psychopathology (e.g. alien hand, anarchic hand, anosognosia for one's own hemiparesis). {\textcopyright} 2008 Elsevier Inc. All rights reserved.},
author = {Synofzik, Matthis and Vosgerau, Gottfried and Newen, Albert},
doi = {10.1016/j.concog.2008.03.008},
isbn = {1090-2376 (Electronic)$\backslash$r1053-8100 (Linking)},
issn = {10538100},
journal = {Consciousness and Cognition},
keywords = {Agency,Alien hand,Anosognosia,Ownership,Self-representation},
number = {2},
pages = {411--424},
pmid = {18411059},
title = {{I move, therefore I am: A new theoretical framework to investigate agency and ownership}},
volume = {17},
year = {2008}
}
@article{Tseng2007,
abstract = {The cerebellum is an essential part of the neural network involved in adapting goal-directed arm movements. This adaptation might rely on two distinct signals: a sensory prediction error or a motor correction. Sensory prediction errors occur when an initial motor command is generated but the predicted sensory consequences do not match the observed values. In some tasks, these sensory errors are monitored and result in on-line corrective motor output as the movement progresses. Here we asked whether cerebellum-dependent adaptation of reaching relies on sensory or on-line motor corrections. Healthy controls and people with hereditary cerebellar ataxia reached during a visuomotor perturbation in two conditions: "shooting" movements without on-line corrections and "pointing" movements that allowed for on-line corrections. Sensory (i.e., visual) errors were available in both conditions. Results showed that the addition of motor corrections did not influence adaptation in control subjects, suggesting that only sensory errors were needed for learning. Cerebellar subjects were comparably impaired in both adaptation conditions relative to controls, despite abnormal and inconsistent on-line motor correction. Specifically, poor on-line motor corrections were unrelated to cerebellar subjects' adaptation deficit (i.e., adaptation did not worsen), further suggesting that only sensory prediction errors influence this process. Therefore adaptation to visuomotor perturbations depends on the cerebellum and is driven by the mismatch between predicted and actual sensory outcome of motor commands.},
author = {Tseng, Y.-w. and Diedrichsen, J. and Krakauer, J. W. and Shadmehr, R. and Bastian, A. J.},
doi = {10.1152/jn.00266.2007},
isbn = {0022-3077 (Print) 0022-3077 (Linking)},
issn = {0022-3077},
journal = {Journal of Neurophysiology},
number = {1},
pages = {54--62},
pmid = {17507504},
title = {{Sensory Prediction Errors Drive Cerebellum-Dependent Adaptation of Reaching}},
url = {http://jn.physiology.org/cgi/doi/10.1152/jn.00266.2007},
volume = {98},
year = {2007}
}
@article{Synofzik2010,
abstract = {The experience of being the initiator of one's own actions seems to be infallible at first glance. Misattributions of agency of one's actions in certain neurological or psychiatric patients reveal, however, that the central mechanisms underlying this experience can go astray. In particular, delusions of influence in schizophrenia might result from deficits in an inferential mechanism that allows distinguishing whether or not a sensory event has been self-produced. This distinction is made by comparing the actual sensory information with the consequences of one's action as predicted on the basis of internal action-related signals such as efference copies. If this internal prediction matches the actual sensory event, an action is registered as self-caused; in case of a mismatch, the difference is interpreted as externally produced. We tested the hypothesis that delusions of influence are based on deficits in this comparator mechanism. In particular, we tested whether patients' impairments in action attribution tasks are caused by imprecise predictions about the sensory consequences of self-action. Schizophrenia patients and matched controls performed pointing movements in a virtual-reality setup in which the visual consequences of movements could be rotated with respect to the actual movement. Experiment 1 revealed higher thresholds for detecting experimental feedback rotations in the patient group. The size of these thresholds correlated positively with patients' delusions of influence. Experiment 2 required subjects to estimate their direction of pointing visually in the presence of constantly rotated visual feedback. When compared to controls, patients' estimates were significantly better adapted to the feedback rotation and exhibited an increased variability. In interleaved trials without visual feedback, i.e. when pointing estimates relied solely on internal action-related signals, this variability was likewise increased and correlated with both delusions of influence and the size of patients' detection thresholds as assessed in the first experiment. These findings support the notion that delusions of influence are based on imprecise internal predictions about the sensory consequences of one's actions. Moreover, we suggest that such imprecise predictions prompt patients to rely more strongly on (and thus adapt to) external agency cues, in this case vision. Such context-dependent weighted integration of imprecise internal predictions and alternative agency cues might thus reflect the common basis for the various misattributions of agency in schizophrenia patients.},
author = {Synofzik, Matthis and Thier, Peter and Leube, Dirk T. and Schlotterbeck, Peter and Lindner, Axel},
doi = {10.1093/brain/awp291},
isbn = {1460-2156 (Electronic)$\backslash$n0006-8950 (Linking)},
issn = {14602156},
journal = {Brain},
keywords = {Agency,Bayes,Efference copy,Optimal cue integration,Perception,Schizophrenia,Self},
number = {1},
pages = {262--271},
pmid = {19995870},
title = {{Misattributions of agency in schizophrenia are based on imprecise predictions about the sensory consequences of one's actions}},
volume = {133},
year = {2010}
}
@article{tHart2016,
abstract = {During motor adaptation the discrepancy between predicted and actually perceived sensory feedback is thought to be minimized, but it can be difficult to measure predictions of the sensory consequences of actions. Studies attempting to do so have found that self-directed, unseen hand position is mislocalized in the direction of altered visual feedback. However, our lab has shown that motor adaptation also leads to changes in perceptual estimates of hand position, even when the target hand is passively displaced. We attribute these changes to a recalibration of hand proprioception, since in the absence of a volitional movement, efferent or predictive signals are likely not involved. The goal here is to quantify the extent to which changes in hand localization reflect a change in the predicted sensory (visual) consequences or a change in the perceived (proprioceptive) consequences. We did this by comparing changes in localization produced when the hand movement was self-generated ('active localization') versus robot-generated ('passive localization') to the same locations following visuomotor adaptation to a rotated cursor. In this passive version, there should be no predicted consequences of these robot-generated hand movements. We found that although changes in localization were somewhat larger in active localization, the passive localization task also elicited substantial changes. Our results suggest that the change in hand localization following visuomotor adaptation may not be based entirely on updating predicted sensory consequences, but may largely reflect changes in our proprioceptive state estimate.},
author = {{'t Hart}, Bernard Marius and Henriques, Denise Y.P.},
doi = {10.1371/journal.pone.0163556},
journal = {PLoS ONE},
number = {9},
pages = {1--15},
pmid = {27658214},
title = {{Separating predicted and perceived sensory consequences of motor learning}},
volume = {11},
year = {2016}
}
@article{Ruttle2016,
abstract = {Training to reach with rotated visual feedback results in adaptation of hand movements, which persist when the perturbation is removed (reach aftereffects). Training also leads to changes in felt hand position, which we refer to as proprioceptive recalibration. The rate at which motor and proprioceptive changes develop throughout training is unknown. Here, we aim to determine the timescale of these changes in order to gain insight into the processes that may be involved in motor learning. Following six rotated reach training trials (30 degrees rotation), at three radially located targets, we measured reach aftereffects and perceived hand position (proprioceptive guided reaches). Participants trained with opposing rotations one week apart to determine if the original training led to any retention or interference. Results suggest that both motor and proprioceptive recalibration occurred in as few as six rotated-cursor training trials (7.57 degrees {\&} 3.88 degrees E respectively), with no retention or interference present one week after training. Despite the rapid speed of both motor and sensory changes, these shifts do not saturate to the same degree. Thus, different processes may drive these changes and they may not constitute a single implicit process.},
author = {Ruttle, Jennifer E. and Cressman, Erin K. and {'t Hart}, Bernard Marius and Henriques, Denise Y.P.},
doi = {10.1371/journal.pone.0163695},
isbn = {1932-6203},
issn = {19326203},
journal = {PLoS ONE},
number = {10},
pages = {1--16},
pmid = {27732595},
title = {{Time course of reach adaptation and proprioceptive recalibration during visuomotor learning}},
volume = {11},
year = {2016}
}
@article{Wilke2013,
abstract = {Sensorimotor learning critically depends on error signals. Learning usually tries to minimise these error signals to guarantee optimal performance. Errors can, however, have both internal causes, resulting from one's sensorimotor system, and external causes, resulting from external disturbances. Does learning take into account the perceived cause of error information? Here, we investigated the recalibration of internal predictions about the sensory consequences of one's actions. Since these predictions underlie the distinction of self- and externally produced sensory events, we assumed them to be recalibrated only by prediction errors attributed to internal causes. When subjects were confronted with experimentally induced visual prediction errors about their pointing movements in virtual reality, they recalibrated the predicted visual consequences of their movements. Recalibration was not proportional to the externally generated prediction error, but correlated with the error component which subjects attributed to internal causes. We also revealed adaptation in subjects' motor performance which reflected their recalibrated sensory predictions. Thus, causal attribution of error information is essential for sensorimotor learning.},
author = {Wilke, Carlo and Synofzik, Matthis and Lindner, Axel},
doi = {10.1371/journal.pone.0054925},
isbn = {19326203},
issn = {19326203},
journal = {PLoS ONE},
number = {1},
pmid = {23359818},
title = {{Sensorimotor Recalibration Depends on Attribution of Sensory Prediction Errors to Internal Causes}},
volume = {8},
year = {2013}
}
@article{RC1996,
author = {RC, Miall and M, Wolpert D},
isbn = {1879-2782 (Electronic) 0893-6080 (Linking)},
journal = {Neural Networks},
number = {8},
pages = {1265--1279},
pmid = {12662535},
title = {{Forward Models for phyiological motor control}},
volume = {9},
year = {1996}
}
@article{Wickens1990,
abstract = {On the basis of behavioural evidence, dopamine is found to be involved in two higher-level functions of the brain: reward-mediated learning and motor activation. In these functions dopamine appears to mediate synaptic enhancement in the corticostriatal pathway. However, in electrophysiological studies, dopamine is often reported to inhibit corticostriatal transmission. These two effects of dopamine seem incompatible. The existence of separate populations of dopamine receptors, differentially modulating cholinergic and glutamatergic synapses, suggests a possible resolution to this paradox. The synaptic enhancement which occurs in reward-mediated learning may also be involved in dopamine-mediated motor activation. The logical form of reward-mediated learning imposes constraints on which mechanisms can be considered possible. Dopamine D1 receptors may mediate enhancement of corticostriatal synapses. On the other hand, dopamine D2 receptors on cholinergic terminals may mediate indirect, inhibitory effects of dopamine on striatal neurons.},
author = {Wickens, J.},
doi = {10.1007/BF01245020},
isbn = {0300-9564 (Print)$\backslash$r0300-9564 (Linking)},
issn = {03009564},
journal = {Journal of Neural Transmission},
keywords = {Dopamine,motor activation,reward,striatum,synaptic modification},
number = {1},
pages = {9--31},
pmid = {2407269},
title = {{Striatal dopamine in motor activation and reward-mediated learning: steps towards a unifying model}},
volume = {80},
year = {1990}
}
@article{Wickens2003,
abstract = {The analysis of the neural mechanisms responsible for reward-related learning has benefited from recent studies of the effects of dopamine on synaptic plasticity. Dopamine-dependent synaptic plasticity may lead to strengthening of selected inputs on the basis of an activity-dependent conjunction of sensory afferent activity, motor output activity, and temporally related firing of dopamine cells. Such plasticity may provide a link between the reward-related firing of dopamine cells and the acquisition of changes in striatal cell activity during learning. This learning mechanism may play a special role in the translation of reward signals into context-dependent response probability or directional bias in movement responses.},
author = {Wickens, Jeffery R. and Reynolds, John N.J. and Hyland, Brian I.},
doi = {10.1016/j.conb.2003.10.013},
isbn = {0959-4388 (Print)$\backslash$n0959-4388 (Linking)},
issn = {09594388},
journal = {Current Opinion in Neurobiology},
number = {6},
pages = {685--690},
pmid = {14662369},
title = {{Neural mechanisms of reward-related motor learning}},
volume = {13},
year = {2003}
}
@article{Wu2013,
abstract = {The planning of goal-directed movements is highly adaptable; however, the basic mechanisms underlying this adaptability are not well understood. Even the features of movement that drive adaptation are hotly debated, with some studies suggesting remapping of goal locations and others suggesting remapping of the movement vectors leading to goal locations. However, several previous motor learning studies and the multiplicity of the neural coding underlying visually guided reaching movements stand in contrast to this either/or debate on the modes of motor planning and adaptation. Here we hypothesize that, during visuomotor learning, the target location and movement vector of trained movements are separately remapped, and we propose a novel computational model for how motor plans based on these remappings are combined during the control of visually guided reaching in humans. To test this hypothesis, we designed a set of experimental manipulations that effectively dissociated the effects of remapping goal location and movement vector by examining the transfer of visuomotor adaptation to untrained movements and movement sequences throughout the workspace. The results reveal that (1) motor adaptation differentially remaps goal locations and movement vectors, and (2) separate motor plans based on these features are effectively averaged during motor execution. We then show that, without any free parameters, the computational model we developed for combining movement-vector-based and goal-location-based planning predicts nearly 90{\%} of the variance in novel movement sequences, even when multiple attributes are simultaneously adapted, demonstrating for the first time the ability to predict how motor adaptation affects movement sequence planning.},
author = {Wu, H. G. and Smith, M. A.},
doi = {10.1523/JNEUROSCI.3761-12.2013},
isbn = {0270-6474},
issn = {0270-6474},
journal = {Journal of Neuroscience},
number = {26},
pages = {10772--10789},
pmid = {23804099},
title = {{The Generalization of Visuomotor Learning to Untrained Movements and Movement Sequences Based on Movement Vector and Goal Location Remapping}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.3761-12.2013},
volume = {33},
year = {2013}
}
@article{Ramkumar2016,
abstract = {Rewards associated with actions are critical for motivation and learning about the consequences of one's actions on the world. The motor cortices are involved in planning and executing movements, but it is unclear whether they encode reward over and above limb kinematics and dynamics. Here, we report a categorical reward signal in dorsal premotor (PMd) and primary motor (M1) neurons that corresponds to an increase in firing rates when a trial was not rewarded regardless of whether or not a reward was expected. We show that this signal is unrelated to error magnitude, reward prediction error, or other task confounds such as reward consumption, return reach plan, or kinematic differences across rewarded and unrewarded trials. The availability of reward information in motor cortex is crucial for theories of reward-based learning and motivational influences on actions.},
author = {Ramkumar, Pavan and Dekleva, Brian and Cooler, Sam and Miller, Lee and Kording, Konrad},
doi = {10.1371/journal.pone.0160851},
issn = {19326203},
journal = {PLoS ONE},
number = {8},
pages = {1--13},
pmid = {27564707},
title = {{Premotor and motor cortices encode reward}},
volume = {11},
year = {2016}
}
@article{Wolpert2001,
abstract = {Movement provides the only means we have to interact with both the world and other people. Such interactions can be hard-wired or learned through experience with the environment. Learning allows us to adapt to a changing physical environment as well as to novel conventions developed by society. Here we review motor learning from a computational perspective, exploring the need for motor learning, what is learned and how it is represented, and the mechanisms of learning. We relate these computational issues to empirical studies on motor learning in humans.},
author = {Wolpert, Daniel M. and Ghahramani, Zoubin and Flanagan, J. Randall},
doi = {10.1016/S1364-6613(00)01773-3},
isbn = {1364-6613 (Print)},
issn = {13646613},
journal = {Trends in Cognitive Sciences},
number = {11},
pages = {487--494},
pmid = {11684481},
title = {{Perspectives and problems in motor learning}},
volume = {5},
year = {2001}
}
@article{Wolpert1998,
abstract = {This review will focus on the possibility that the cerebellum contains an internal model or models of the motor apparatus. Inverse internal models can provide the neural command necessary to achieve some desired trajectory. First, we review the necessity of such a model and the evidence, based on the ocular following response, that inverse models are found within the cerebellar circuitry. Forward internal models predict the consequences of actions and can be used to overcome time delays associated with feedback control. Secondly, we review the evidence that the cerebellum generates predictions using such a forward model. Finally, we review a computations model that includes multiple paired forward and inverse models and show how such an arrangement can be advantageous for motor learning and control.},
author = {Wolpert, Daniel M. and Miall, R. Chris and Kawato, Mitsuo},
doi = {10.1016/S1364-6613(98)01221-2},
isbn = {1364-6613 (Print)$\backslash$r1364-6613 (Linking)},
issn = {13646613},
journal = {Trends in Cognitive Sciences},
number = {9},
pages = {338--347},
pmid = {21227230},
title = {{Internal models in the cerebellum}},
volume = {2},
year = {1998}
}
@article{Clayton2014,
abstract = {Reaching movements are rapidly adapted following training with rotated visual feedback of the hand (motor recalibration). Our laboratory has also found that visuomotor adaptation results in changes in estimates of felt hand position (proprioceptive recalibration) in the direction of the visuomotor distortion (Cressman and Henriques 2009, 2010; Cressman et al. 2010). In the present study, we included an additional method for measuring hand proprioception [specifically, proprioceptive-guided reaches of the unadapted (left) hand to the robot-guided adapted (right) hand-target] and compared this with our original perceptual task (estimating the felt hand position of the adapted hand relative to visual reference markers/the body midline), as well as to no-cursor reaches with the adapted hand (reaching to visual and midline-targets), to better identify whether changes in reaching following adaptation to a 50° rightward-rotated cursor reflect sensory or motor processes. Results for the proprioceptive estimation task were consistent with previous findings; subjects felt their hand to be aligned with a reference marker when it was shifted approximately 4° more in the direction of the visuomotor distortion following adaptation compared with baseline conditions. Moreover, we found similar changes in the proprioceptive-guided reaching task such that subjects misreached 5° in the direction of the cursor rotation. However, these results were true only for proprioceptive-guided reaches to the adapted hand, as reaches to the body midline were not affected by adaptation. This suggests that proprioceptive recalibration is restricted to the adapted hand and does not generalize to the rest of the body; this truly reflects a change in the sensory representation of the hand rather than changes in the motor program. This is in contrast to no-cursor reaches made with the adapted hand, which show reach after-effects for both visual targets and the midline, suggesting that reaches with the adapted hand reflect more of a change in the motor system. Our results also shed light on previous studies that may have misattributed these sensory and motor changes.},
author = {Clayton, Holly A. and Cressman, Erin K. and Henriques, Denise Y P},
doi = {10.1007/s00221-014-3896-y},
file = {:home/marius/Dropbox/SensConseq/lit/Clayton et al (Cressman Henriques) 2014.ExpBrainRes.232.7.2073.pdf:pdf},
isbn = {0022101438},
issn = {14321106},
journal = {Experimental Brain Research},
keywords = {Multi-sensory integration,Proprioception,Proprioceptive recalibration,Reaching,Visuomotor adaptation},
number = {7},
pages = {2073--2086},
pmid = {24623356},
title = {{The effect of visuomotor adaptation on proprioceptive localization: The contributions of perceptual and motor changes}},
volume = {232},
year = {2014}
}
@article{Cameron2012,
abstract = {Research suggests that perceptual experience of our movements adapts together with movement control when we are the agents of our actions. Is this agency critical for perceptual and motor adaptation? We had participants view cursor feedback during elbow extension-flexion movements when they (1) actively moved their arm, or (2) had their arm passively moved. We probed adaptation of movement perception by having participants report the reversal point of their unseen movement. We probed adaptation of movement control by having them aim to a target. Perception and control of active movement were influenced by both types of exposure, although adaptation was stronger following active exposure. Furthermore, both types of exposure led to a change in the perception of passive movements. Our findings support the notion that perception and control adapt together, and they suggest that some adaptation is due to recalibrated proprioception that arises independently of active engagement with the environment. {\textcopyright} 2010 Elsevier Inc.},
author = {Cameron, Brendan D. and Franks, Ian M. and Inglis, J. Timothy and Chua, Romeo},
doi = {10.1016/j.concog.2010.11.006},
file = {:home/marius/Dropbox/SensConseq/lit/Cameron et al 2012.ConsciousCogn.21.1.4.pdf:pdf},
isbn = {1053-8100$\backslash$r1090-2376},
issn = {10538100},
journal = {Consciousness and Cognition},
keywords = {Active exposure,Adaptation,Agency,Passive exposure,Proprioception},
number = {1},
pages = {4--17},
pmid = {21111638},
publisher = {Elsevier Inc.},
title = {{The adaptability of self-action perception and movement control when the limb is passively versus actively moved}},
url = {http://dx.doi.org/10.1016/j.concog.2010.11.006},
volume = {21},
year = {2012}
}
@article{Christensen2014,
abstract = {It is widely accepted that action and perception in humans functionally interact on multiple levels. Moreover, areas originally suggested to be predominantly motor-related, as the cerebellum, are also involved in action observation. However, as yet, few studies provided unequivocal evidence that the cerebellum is involved in the action perception coupling (APC), specifically in the integration of motor and multisensory information for perception. We addressed this question studying patients with focal cerebellar lesions in a virtual-reality paradigm measuring the effect of action execution on action perception presenting self-generated movements as point lights. We measured the visual sensitivity to the point light stimuli based on signal detection theory. Compared with healthy controls cerebellar patients showed no beneficial influence of action execution on perception indicating deficits in APC. Applying lesion symptom mapping, we identified distinct areas in the dentate nucleus and the lateral cerebellum of both hemispheres that are causally involved in APC. Lesions of the right ventral dentate, the ipsilateral motor representations (lobules V/VI), and most interestingly the contralateral posterior cerebellum (lobule VII) impede the benefits of motor execution on perception. We conclude that the cerebellum establishes time-dependent multisensory representations on different levels, relevant for motor control as well as supporting action perception. Ipsilateral cerebellar motor representations are thought to support the somatosensory state estimate of ongoing movements, whereas the ventral dentate and the contralateral posterior cerebellum likely support sensorimotor integration in the cerebellar-parietal loops. Both the correct somatosensory as well as the multisensory state representations are vital for an intact APC.},
author = {Christensen, A. and Giese, M. A. and Sultan, F. and Mueller, O. M. and Goericke, S. L. and Ilg, W. and Timmann, D.},
doi = {10.1523/JNEUROSCI.3276-13.2014},
file = {:home/marius/Dropbox/SensConseq/lit/Christensen et al (Giese Ilg) 2014.JNeurosci.34.19.6707.pdf:pdf},
isbn = {1529-2401 (Electronic)$\backslash$n0270-6474 (Linking)},
issn = {0270-6474},
journal = {Journal of Neuroscience},
keywords = {action perception coupling,biological motion,cerebellum,lesion symptom mapping},
number = {19},
pages = {6707--6716},
pmid = {24806697},
title = {{An Intact Action-Perception Coupling Depends on the Integrity of the Cerebellum}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.3276-13.2014},
volume = {34},
year = {2014}
}
@article{Cressman2010,
abstract = {Cressman EK, Henriques DY. Reach adaptation and proprioceptive recalibration following exposure to misaligned sensory input. Motor adaptation in response to a visuo-motor distortion arises when the usual motor command no longer results in the predicted sensory output. In this study, we examined if exposure to a sensory discrepancy was sufficient on its own to produce changes in reaches and recalibrate the sense of felt hand position in the absence of any voluntary movements. Subjects pushed their hand out along a robot-generated fixed linear path (active exposure group) or were passively moved along the same path (passive exposure group). This fixed path was gradually rotated counterclockwise around the home position with respect to the path of the cursor. On all trials, subjects saw the cursor head directly to the remembered target position while their hand moved outwards. We found that after exposure to the visually distorted hand motion, subjects in both groups adapted their reaches such that they aimed ϳ6° to the left of the intended target. The magnitude of reach adaptation was similar to the extent that subjects recalibrated their sense of felt hand position. Specifically the position at which subjects perceived their unseen hand to be aligned with a reference marker was the same as that to which they reached when allowed to move freely. Given the similarity in magnitude of these adaptive responses we propose that reach adaptation arose due to changes in subjects' sense of felt hand position. Moreover, results indicate that motor adaptation can arise following exposure to a sensory mismatch in the absence of movement related error signals.},
author = {Cressman, E. K. and Henriques, D. Y. P.},
doi = {10.1152/jn.01002.2009},
file = {:home/marius/Dropbox/SensConseq/lit/Cressman and Henriques 2010.JNeurophys.103.4.1888.pdf:pdf},
isbn = {1155511557},
issn = {0022-3077},
journal = {Journal of Neurophysiology},
number = {4},
pages = {1888--1895},
pmid = {20130036},
title = {{Reach Adaptation and Proprioceptive Recalibration Following Exposure to Misaligned Sensory Input}},
url = {http://jn.physiology.org/cgi/doi/10.1152/jn.01002.2009},
volume = {103},
year = {2010}
}
@article{Carruthers2009,
abstract = {Synofzik, Vosgerau, and Newen (2008) offer a powerful explanation of the sense of agency. To argue for their model they attempt to show that one of the standard models (the comparator model) fails to explain the sense of agency and that their model offers a more general account than is aimed at by the standard model. Here I offer comment on both parts of this argument. I offer an alternative reading of some of the data they use to argue against the comparator model. I argue that contrary to Synofzik, Vosgerau and Newen's reading the case of G.L. supports rather than contradicts the comparator model. Next I suggest how the comparator model can differentiate failures of action attribution in patients suffering parietal lobe lesions and delusions of alien control. I also argue that the apparently unexpected phenomenon of ‘‘hyperassociation” is predicted by the comparator model. Finally I suggest that as it stands Synofzik, Vosgerau and Newen's model is not well specified enough to explain deficits in the sense of agency associated with delusions of thought insertion. Thus they have not met their second argumentative burden of showing how their model is more general than the comparator model.},
author = {Carruthers, Glenn},
doi = {10.1016/j.concog.2008.05.006},
file = {:home/marius/Dropbox/SensConseq/lit/Carruthers 2009.ConsciousCogn.18.2.515.pdf:pdf},
isbn = {1053-8100},
issn = {10538100},
journal = {Consciousness and Cognition},
number = {2},
pages = {515--520},
pmid = {18586521},
publisher = {Elsevier Inc.},
title = {{Commentary on Synofzik, Vosgerau and Newen 2008}},
url = {http://dx.doi.org/10.1016/j.concog.2008.05.006},
volume = {18},
year = {2009}
}
@article{Cressman2011,
abstract = {Goal-directed reaches are rapidly adapted after reaching with misaligned visual feedback of the hand. It has been suggested that reaching with misaligned visual feedback of the hand also results in proprioceptive recalibration (i.e., realigning proprioceptive estimates of hand position to match visual estimates). In this chapter, we review a series of experiments conducted in our lab which examine this proposal. We assessed proprioceptive recalibration by comparing subjects' estimates of the position at which they felt their hand was aligned with a reference marker (visual or proprioceptive) before and after aiming with a misaligned cursor that was typically rotated 30° clockwise (CW) with respect to the hand. In general, results indicated that subjects recalibrated proprioception such that their estimates of felt hand position were shifted in the same direction that they adapted their reaches. Moreover, proprioception was recalibrated to a similar extent of motor adaptation (∼ 30{\%}), regardless of how the hand was positioned during the estimate trials (active or passive placement), the location or modality of the reference marker (visual or proprioceptive), the hand used during reach training (right or left), how the distortion was introduced (gradual or abrupt), and age (young or older subjects) and the magnitude of the visuomotor distortion introduced (30° or 50° or 70°). These results suggest that in addition to recalibrating the sensorimotor transformations underlying reaching movements, visuomotor adaptation results in partial proprioceptive recalibration. {\textcopyright} 2011 Elsevier B.V.},
author = {Cressman, Erin K. and Henriques, Denise Y P},
doi = {10.1016/B978-0-444-53752-2.00011-4},
file = {:home/marius/Dropbox/SensConseq/lit/Cressman and Henriques 2011.ProgBrainRes.191.91.pdf:pdf},
isbn = {9780444537522},
issn = {18757855},
journal = {Progress in Brain Research},
keywords = {Proprioception,Sensory recalibration,Visuomotor adaptation},
pages = {91--99},
pmid = {21741546},
title = {{Motor adaptation and proprioceptive recalibration}},
volume = {191},
year = {2011}
}
